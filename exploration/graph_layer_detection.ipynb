{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111928c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec1324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bioimageio_utils.py (2): pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "import hdbscan\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "from scipy.spatial import Delaunay\n",
    "from src.models.model_loader import ModelLoader\n",
    "from src.utils.helpers import compare_two_images\n",
    "from skimage.measure import label\n",
    "from scipy.spatial import Delaunay\n",
    "from collections import defaultdict\n",
    "from stardist.models import StarDist2D\n",
    "from stardist.plot import render_label\n",
    "from src.utils.helpers import cut_out_image\n",
    "from skimage.exposure import rescale_intensity\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cosine\n",
    "from math import acos, degrees\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d531c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load four images, which present a good example of layers\n",
    "LAYER_PATH = project_root / \"data/layer_examples\"\n",
    "\n",
    "paths = [(LAYER_PATH / image_path) for image_path in os.listdir(LAYER_PATH)]\n",
    "images = list(map(tifffile.imread, paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ffcb851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "from src.utils.reinhard_normalizer import ReinhardNormalizer\n",
    "\n",
    "normalizer = ReinhardNormalizer()\n",
    "images = [normalizer.normalize(img) for img in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810273df",
   "metadata": {},
   "source": [
    "# Create Tissue Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a13015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CNN: unet_2c\n"
     ]
    }
   ],
   "source": [
    "# Specify model to load\n",
    "model_loader = ModelLoader()\n",
    "MODEL_CFG = \"unet_2\"\n",
    "model = model_loader.load_cnn_model(MODEL_CFG, \"unet_2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0c2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessing import inference_processing\n",
    "from skimage.transform import resize\n",
    "ORG_RES = (1920, 2560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e296f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "masks = []\n",
    "labeled_tissues = []\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "print(device)\n",
    "for img in images:\n",
    "    img = inference_processing(img, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_logits = model(img)\n",
    "        pred_mask = torch.argmax(pred_logits, dim=1).squeeze()\n",
    "        pred_mask = pred_mask.cpu().numpy()\n",
    "        pred_mask = resize(pred_mask, ORG_RES, anti_aliasing=True)\n",
    "    labeled_tissue = label(pred_mask > 0, connectivity=2)\n",
    "    labeled_tissues.append(labeled_tissue)\n",
    "    masks.append(pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "275b41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, mask in zip(images, masks):\n",
    "#     compare_two_images(img, mask, \"Normalized Image\", \"Predicted Mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f62f9",
   "metadata": {},
   "source": [
    "# Segment Nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5448279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_he' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.692478, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "stardist_model = StarDist2D.from_pretrained(\"2D_versatile_he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b62b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_masks = []\n",
    "nuclei_data_dicts = []\n",
    "\n",
    "for img, mask in zip(images, masks):\n",
    "    image_normed = rescale_intensity(img, out_range=(0, 1))\n",
    "    labels, data_dict = stardist_model.predict_instances(image_normed, axes='YXC', prob_thresh=0.25, nms_thresh=0.01, return_labels=True)\n",
    "    filtered_labels = cut_out_image(labels, mask)\n",
    "    binary_labels = (filtered_labels > 0).astype(np.uint8)\n",
    "    nuclei_masks.append(binary_labels)\n",
    "    nuclei_data_dicts.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71892af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, mask in zip(images, nuclei_masks):\n",
    "#     compare_two_images(img, mask, \"Normalized Image\", \"Filtered nuclei mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3625426",
   "metadata": {},
   "source": [
    "# Clean Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfee0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_area(x,y):\n",
    "    return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c0a3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_area(coordinates: np.ndarray) -> float:\n",
    "    areas = []\n",
    "    for coord in coordinates:\n",
    "        area = poly_area(np.array(coord[0]), np.array(coord[1]))\n",
    "        areas.append(area)\n",
    "    \n",
    "    median_area = np.median(np.array(areas))\n",
    "    return median_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2af1fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_dict_mask(mask: np.ndarray, data_dict: dict[str, any]) -> list:\n",
    "    points = data_dict[\"points\"]\n",
    "    filtered_points = []\n",
    "    binary_mask = (mask > 0).astype(int)\n",
    "    for point, coord in zip(points, data_dict[\"coord\"]):\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        if binary_mask[x, y] == 1:\n",
    "            filtered_points.append([point[0], point[1]])\n",
    "\n",
    "    filtered_data_dict = dict(data_dict)\n",
    "    filtered_data_dict[\"points\"] = np.array(filtered_points)\n",
    "    \n",
    "    return filtered_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf97cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_dict(mask: np.ndarray, data_dict: dict[str, any], area_th: float = 0.5) -> list:\n",
    "    points = data_dict[\"points\"]\n",
    "    median_area = calculate_median_area(data_dict[\"coord\"])\n",
    "    filtered_points = []\n",
    "    filtered_coords = []\n",
    "    filtered_probs = []\n",
    "\n",
    "    binary_mask = (mask > 0).astype(int)\n",
    "    for i, (point, coord) in enumerate(zip(points, data_dict[\"coord\"])):\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        area = poly_area(np.array(coord[0]), np.array(coord[1]))\n",
    "        if binary_mask[x, y] == 1 and area > area_th * median_area:\n",
    "            filtered_points.append([point[0], point[1]])\n",
    "            filtered_coords.append(coord)\n",
    "            filtered_probs.append(data_dict[\"prob\"][i])\n",
    "\n",
    "    filtered_data_dict = dict(data_dict)\n",
    "    filtered_data_dict[\"points\"] = np.array(filtered_points)\n",
    "    filtered_data_dict[\"coord\"] = np.array(filtered_coords)\n",
    "    filtered_data_dict[\"prob\"] = np.array(filtered_probs)\n",
    "    \n",
    "    return filtered_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4de4fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_points(image: np.ndarray, data_dict: dict[str,np.ndarray]) -> None:\n",
    "    points = data_dict[\"points\"]\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    n_points = len(points)\n",
    "    random_values = np.random.rand(n_points)\n",
    "    plt.scatter(points[:, 1], points[:, 0], s=5, c=random_values, cmap='tab20')\n",
    "    plt.xlim(0, width)\n",
    "    plt.ylim(height, 0)\n",
    "    plt.axis(\"off\")\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e3428ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dict = nuclei_data_dicts[1]\n",
    "len(test_data_dict[\"points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5591b54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_test_data_dict = filter_data_dict(masks[1], test_data_dict)\n",
    "len(filter_test_data_dict[\"points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5954173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_data_dict = filter_data_dict_mask(masks[1], test_data_dict)\n",
    "len(mask_data_dict[\"points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229f3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, mask, data_dict in zip(images, masks, nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(mask, data_dict)\n",
    "#     plot_image_and_points(image, filtered_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b35429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_points(image: np.ndarray, data_dict: dict[str,np.ndarray], ax=None) -> None:\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        show_plot = True\n",
    "    else:\n",
    "        show_plot = False\n",
    "    \n",
    "    points = data_dict[\"points\"]\n",
    "    plt.imshow(image)\n",
    "    n_points = len(points)\n",
    "    random_values = np.random.rand(n_points)\n",
    "    plt.scatter(points[:, 1], points[:, 0], \n",
    "             c=random_values, cmap='tab20', s=15, alpha=1)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71566e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images_with_points(image_1: np.ndarray, data_dict_1: dict[str,np.ndarray], image_2: np.ndarray, data_dict_2: dict[str, np.ndarray]) -> None:\n",
    "    plt.figure(figsize=(18, 12))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    points_1 = data_dict_1[\"points\"]\n",
    "    plt.imshow(image_1)\n",
    "    plt.plot(points_1[:, 1], points_1[:, 0], 'o', \n",
    "             color='blue', markersize=3, alpha=0.8)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    points_2 = data_dict_2[\"points\"]\n",
    "    plt.imshow(image_2)\n",
    "    plt.plot(points_2[:, 1], points_2[:, 0], 'o', \n",
    "             color='blue', markersize=3, alpha=0.8)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e649bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, mask, data_dict in zip(images, masks, nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(mask, data_dict)\n",
    "#     plot_image_with_points(image, filtered_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c0932c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compare\n",
    "# for image, mask, data_dict in zip(images, masks, nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(mask, data_dict)\n",
    "#     compare_images_with_points(image, filtered_data_dict, image, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9932a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompute_nuclei_centers(data_dict: dict[str,any]) -> dict[str,any]:\n",
    "    points = data_dict[\"points\"]\n",
    "    corrected_points = []\n",
    "    coords = data_dict[\"coord\"]\n",
    "    for i, coord in enumerate(coords):\n",
    "        mean_x = np.round(np.mean(coord[0]))\n",
    "        mean_y = np.round(np.mean(coord[1]))\n",
    "        corrected_points.append([mean_x, mean_y])\n",
    "    \n",
    "    recentered_dict = dict(data_dict)\n",
    "    recentered_dict[\"points\"] = np.array(corrected_points)\n",
    "\n",
    "    return recentered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "24af0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recompute nuclei and compare\n",
    "# for image, mask, data_dict in zip(images, masks, nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(mask, data_dict)\n",
    "#     centered_data_dict = recompute_nuclei_centers(filtered_data_dict)\n",
    "#     compare_images_with_points(image, filtered_data_dict, image, centered_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ff95da",
   "metadata": {},
   "source": [
    "# Graph Layer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a238b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbors\n",
    "\n",
    "def get_delaunay_neighbors(points):\n",
    "    points = np.array(points)\n",
    "    tri = Delaunay(points)\n",
    "    \n",
    "    neighbors = defaultdict(set)\n",
    "    \n",
    "    for simplex in tri.simplices:\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i != j:\n",
    "                    neighbors[simplex[i]].add(simplex[j])\n",
    "    \n",
    "    return dict(neighbors), points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "435efbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nucleus_orientation(boundary_points):\n",
    "    boundary_points = np.array(boundary_points)\n",
    "    \n",
    "    if boundary_points.shape[0] == 2:\n",
    "        boundary_points = boundary_points.T\n",
    "\n",
    "    # Center the points\n",
    "    centroid = boundary_points.mean(axis=0)\n",
    "    centered = boundary_points - centroid\n",
    "    \n",
    "    # PCA to find main axis\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(centered)\n",
    "    \n",
    "    # First principal component is the main axis\n",
    "    main_axis = pca.components_[0]\n",
    "    \n",
    "    return main_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1752d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alignment_similarity(main_axis: np.ndarray, compared_axis: np.ndarray) -> float:\n",
    "    norm_main = np.linalg.norm(main_axis)\n",
    "    norm_compared = np.linalg.norm(compared_axis)\n",
    "    \n",
    "    if norm_main == 0 or norm_compared == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    cosine_similarity = np.dot(main_axis, compared_axis) / (norm_main * norm_compared)\n",
    "    return np.abs(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f39ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alignment_angle(main_point: tuple[int, int], compared_point: tuple[int, int], main_axis: np.ndarray) -> int:\n",
    "    direction_vector = np.array([\n",
    "        compared_point[0] - main_point[0],\n",
    "        compared_point[1] - main_point[1]\n",
    "    ])\n",
    "    \n",
    "    direction_norm = np.linalg.norm(direction_vector)\n",
    "    if direction_norm == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    direction_vector = direction_vector / direction_norm\n",
    "    main_axis = main_axis / np.linalg.norm(main_axis)\n",
    "    \n",
    "    cos_angle = np.clip(np.dot(direction_vector, main_axis), -1.0, 1.0)\n",
    "    \n",
    "    # Calculate angle in radians, then convert to degrees\n",
    "    angle_rad = acos(cos_angle)\n",
    "    angle_deg = degrees(angle_rad)\n",
    "    \n",
    "    if angle_deg > 90:\n",
    "        angle_deg = 180 - angle_deg\n",
    "    angle_deg = 90 - angle_deg\n",
    "    \n",
    "    return np.round(angle_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e61fa402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(main_point: np.ndarray, compared_point: np.ndarray) -> float:\n",
    "    return np.linalg.norm(main_point - compared_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a04813e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_score(alignment: float, angle: float, weights: np.ndarray = np.array([0.5, 0.5])) -> float:\n",
    "    alignment_score = alignment\n",
    "    angle_score = 1.0 - (angle / 90.0)\n",
    "    \n",
    "    similarity = np.sum(np.array([alignment_score, angle_score]) * weights)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e5d6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_distance(points: np.ndarray, neighbor_dict: dict[int, set[int]]) -> float:\n",
    "    distances = []\n",
    "    for i, point in enumerate(points):\n",
    "        for neighbor in neighbor_dict[i]:\n",
    "            if i < neighbor:\n",
    "                neighbor_point = points[neighbor]\n",
    "                distances.append(get_distance(point, neighbor_point))\n",
    "    \n",
    "    if len(distances) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return np.median(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb7bb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neighbor_graph(points: np.ndarray, neighbor_dict: dict[int, set[int]], boundary_points: np.ndarray, distance_threshold: float) -> nx.Graph:\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for i, (x, y) in enumerate(points):\n",
    "        G.add_node(i, pos=(x, y))\n",
    "    \n",
    "    for i, point in enumerate(points):\n",
    "        main_boundary = boundary_points[i]\n",
    "        main_axis = get_nucleus_orientation(main_boundary)\n",
    "\n",
    "        for neighbor in neighbor_dict[i]:\n",
    "            neighbor_point = points[neighbor]\n",
    "            distance = get_distance(point, neighbor_point)\n",
    "\n",
    "            if distance <= distance_threshold:\n",
    "                neighbor_boundary = boundary_points[neighbor]\n",
    "                neighbor_axis = get_nucleus_orientation(neighbor_boundary)\n",
    "                \n",
    "                alignment = calculate_alignment_similarity(main_axis, neighbor_axis)\n",
    "                angle = calculate_alignment_angle(point, neighbor_point, main_axis)\n",
    "                \n",
    "\n",
    "                G.add_edge(i, neighbor, distance=distance, alignment=alignment, angle=angle)\n",
    "\n",
    "    for i in G.nodes():\n",
    "        neighbors = list(G.neighbors(i))\n",
    "        if len(neighbors) == 0:\n",
    "            G.nodes[i]['best_similarity'] = 0.0\n",
    "            continue\n",
    "        \n",
    "        neighbor_scores = []\n",
    "        for neighbor in neighbors:\n",
    "            edge_data = G[i][neighbor]\n",
    "            similarity = calculate_similarity_score(\n",
    "                edge_data['alignment'],\n",
    "                edge_data['angle']\n",
    "            )\n",
    "            neighbor_scores.append((neighbor, similarity))\n",
    "        \n",
    "        # Get top 2 neighbors\n",
    "        neighbor_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_two = neighbor_scores[:2]\n",
    "        \n",
    "        # Calculate combined similarity score\n",
    "        if len(top_two) == 2:\n",
    "            best_similarity = (top_two[0][1] + top_two[1][1]) / 2.0\n",
    "        elif len(top_two) == 1:\n",
    "            best_similarity = top_two[0][1]\n",
    "        else:\n",
    "            best_similarity = 0.0\n",
    "        \n",
    "        G.nodes[i]['best_similarity'] = best_similarity\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "733a1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_neighbor_graph(G: nx.Graph, n1: int, n2: int, alignment_threshold: float, angle_threshold: float, distance_threshold: float | None = None) -> bool:\n",
    "    edge = G[n1][n2]\n",
    "\n",
    "    alignment = edge[\"alignment\"]\n",
    "    angle = edge[\"angle\"]\n",
    "    distance = edge[\"distance\"]\n",
    "\n",
    "    alignment_ok = alignment >= alignment_threshold\n",
    "    angle_ok = angle <= angle_threshold\n",
    "    distance_ok = (distance_threshold is None) or (distance <= distance_threshold)\n",
    "\n",
    "    return alignment_ok and angle_ok and distance_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88a824ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_graph_top_n(G: nx.Graph, n: int = 2) -> nx.Graph:\n",
    "    G_filtered = G.copy()\n",
    "\n",
    "    for node in G.nodes():\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        if len(neighbors) <= n:\n",
    "            continue\n",
    "        \n",
    "        neighbor_scores = []\n",
    "        for neighbor in neighbors:\n",
    "            edge_data = G[node][neighbor]\n",
    "            similarity = calculate_similarity_score(\n",
    "                edge_data['alignment'],\n",
    "                edge_data['angle']\n",
    "            )\n",
    "            neighbor_scores.append((neighbor, similarity))\n",
    "        neighbor_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n_neighbors = {neighbor for neighbor, _ in neighbor_scores[:n]}\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in top_n_neighbors and G_filtered.has_edge(node, neighbor):\n",
    "                G_filtered.remove_edge(node, neighbor)\n",
    "        \n",
    "    return G_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebd460f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph_overlay(image: np.ndarray, filtered_graph: nx.Graph, \n",
    "                           node_size: int = 50, edge_width: float = 2.0,\n",
    "                           node_color: str = 'blue', edge_color: str = 'cyan',\n",
    "                           alpha: float = 0.7, ax=None) -> None:\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        show_plot = True\n",
    "    else:\n",
    "        show_plot = False\n",
    "    \n",
    "    # Display image\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    components = list(nx.connected_components(filtered_graph))\n",
    "    n_components = len(components)\n",
    "    cmap = plt.cm.get_cmap('tab20')\n",
    "    colors = [cmap(i / max(n_components - 1, 1)) for i in range(n_components)]\n",
    "\n",
    "    node_to_color = {}\n",
    "    for i, component in enumerate(components):\n",
    "        for node in component:\n",
    "            node_to_color[node] = colors[i]\n",
    "\n",
    "    # Draw edges\n",
    "    for (n1, n2) in filtered_graph.edges():\n",
    "        pos1 = filtered_graph.nodes[n1]['pos']\n",
    "        pos2 = filtered_graph.nodes[n2]['pos']\n",
    "        edge_color = node_to_color[n1]\n",
    "        ax.plot([pos1[1], pos2[1]], [pos1[0], pos2[0]], \n",
    "                color=edge_color, linewidth=edge_width, alpha=alpha)\n",
    "    \n",
    "    # Draw nodes\n",
    "    for node in filtered_graph.nodes():\n",
    "        pos = filtered_graph.nodes[node]['pos']\n",
    "        node_color = node_to_color[node]\n",
    "        ax.scatter(pos[1], pos[0], s=node_size, c=[node_color], \n",
    "                  linewidths=1, alpha=alpha, zorder=5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518b6d9",
   "metadata": {},
   "source": [
    "### Plot created graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f8cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data_dict in enumerate(nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(masks[i], data_dict)\n",
    "#     points = filtered_data_dict[\"points\"]\n",
    "#     neighbor_dict, _ = get_delaunay_neighbors(points)\n",
    "#     boundary_points = filtered_data_dict[\"coord\"]\n",
    "#     dist_threshold = get_median_distance(points, neighbor_dict) * 2\n",
    "#     graph = build_neighbor_graph(points=points, neighbor_dict=neighbor_dict, boundary_points=boundary_points, distance_threshold=dist_threshold)\n",
    "#     visualize_graph_overlay(images[i], graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97511340",
   "metadata": {},
   "source": [
    "### Plot filtered graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ff6ca533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data_dict in enumerate(nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(masks[i], data_dict)\n",
    "#     points = filtered_data_dict[\"points\"]\n",
    "#     neighbor_dict, _ = get_delaunay_neighbors(points)\n",
    "#     boundary_points = filtered_data_dict[\"coord\"]\n",
    "#     dist_threshold = get_median_distance(points, neighbor_dict) * 1.5\n",
    "#     graph = build_neighbor_graph(points=points, neighbor_dict=neighbor_dict, boundary_points=boundary_points, distance_threshold=dist_threshold)\n",
    "#     filtered_graph = nx.subgraph_view(\n",
    "#         graph, \n",
    "#         filter_edge=lambda n1, n2: filter_neighbor_graph(\n",
    "#             graph, n1, n2, \n",
    "#             alignment_threshold=0.6, \n",
    "#             angle_threshold=45.0,\n",
    "#             distance_threshold=None\n",
    "#         )\n",
    "#     )\n",
    "#     visualize_graph_overlay(images[i], filtered_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e65e3",
   "metadata": {},
   "source": [
    "### Plot filtered graph with only top two connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b385c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data_dict in enumerate(nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(masks[i], data_dict)\n",
    "#     points = filtered_data_dict[\"points\"]\n",
    "#     neighbor_dict, _ = get_delaunay_neighbors(points)\n",
    "#     boundary_points = filtered_data_dict[\"coord\"]\n",
    "#     dist_threshold = get_median_distance(points, neighbor_dict) * 1.5\n",
    "#     graph = build_neighbor_graph(points=points, neighbor_dict=neighbor_dict, boundary_points=boundary_points, distance_threshold=dist_threshold)\n",
    "#     top_2_graph = filter_graph_top_n(graph, 2)\n",
    "#     filtered_graph = nx.subgraph_view(\n",
    "#         top_2_graph, \n",
    "#         filter_edge=lambda n1, n2: filter_neighbor_graph(\n",
    "#             graph, n1, n2, \n",
    "#             alignment_threshold=0.6, \n",
    "#             angle_threshold=45.0,\n",
    "#             distance_threshold=None\n",
    "#         )\n",
    "#     )\n",
    "#     visualize_graph_overlay(images[i], filtered_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316890a",
   "metadata": {},
   "source": [
    "### Plot the best_similarity of the nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_nodes_by_similarity(image: np.ndarray, filtered_graph: nx.Graph,\n",
    "                                  node_size: int = 50, alpha: float = 0.7, ax=None) -> None:\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        show_plot = True\n",
    "    else:\n",
    "        show_plot = False\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    similarities = []\n",
    "    positions = []\n",
    "    \n",
    "    for node in filtered_graph.nodes():\n",
    "        similarity = filtered_graph.nodes[node].get('best_similarity', 0.0)\n",
    "        pos = filtered_graph.nodes[node]['pos']\n",
    "        similarities.append(similarity)\n",
    "        positions.append([pos[0], pos[1]])\n",
    "    \n",
    "    if len(similarities) == 0:\n",
    "        print(\"No nodes with best_similarity attribute found\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    similarities = np.array(similarities)\n",
    "    positions = np.array(positions)\n",
    "    \n",
    "    # Create blue-to-red colormap\n",
    "    cmap = plt.cm.get_cmap('viridis')\n",
    "    \n",
    "    # Plot all nodes at once for better performance\n",
    "    scatter = ax.scatter(positions[:, 1], positions[:, 0], \n",
    "                        s=node_size, c=similarities, \n",
    "                        cmap=cmap, alpha=alpha, zorder=5, vmin=0, vmax=1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0431ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data_dict in enumerate(nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(masks[i], data_dict)\n",
    "#     points = filtered_data_dict[\"points\"]\n",
    "#     neighbor_dict, _ = get_delaunay_neighbors(points)\n",
    "#     boundary_points = filtered_data_dict[\"coord\"]\n",
    "#     dist_threshold = get_median_distance(points, neighbor_dict) * 1.5\n",
    "#     graph = build_neighbor_graph(points=points, neighbor_dict=neighbor_dict, boundary_points=boundary_points, distance_threshold=dist_threshold)\n",
    "#     visualize_nodes_by_similarity(images[i], graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692470b0",
   "metadata": {},
   "source": [
    "### Plot axis of nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5909c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis_for_nuclei(boundary_points: np.ndarray) -> np.ndarray:\n",
    "    all_axises = []\n",
    "    for boundary in boundary_points:\n",
    "        axis = get_nucleus_orientation(boundary)\n",
    "        all_axises.append(axis)\n",
    "\n",
    "    return np.array(all_axises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a3bb189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_nuclei_axes(image: np.ndarray, points: np.ndarray, axes: np.ndarray,\n",
    "                          line_length: float = 25.0, point_size: int = 30,\n",
    "                          line_color: str = 'green', point_color: str = 'blue',\n",
    "                          alpha: float = 0.8, linewidth: float = 2.0, ax=None) -> None:\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        show_plot = True\n",
    "    else:\n",
    "        show_plot = False\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    for point, axis in zip(points, axes):\n",
    "        # Calculate line endpoints (extending in both directions)\n",
    "        start_point = point - axis * line_length\n",
    "        end_point = point + axis * line_length\n",
    "        \n",
    "        # Draw line through the point\n",
    "        ax.plot([start_point[1], end_point[1]], \n",
    "               [start_point[0], end_point[0]],\n",
    "               color=line_color, linewidth=linewidth, alpha=alpha, zorder=4)\n",
    "    \n",
    "    ax.scatter(points[:, 1], points[:, 0], s=point_size, c=point_color,\n",
    "              alpha=0.5, zorder=5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1c34918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data_dict in enumerate(nuclei_data_dicts):\n",
    "#     boundary_points = data_dict[\"coord\"]\n",
    "#     points = data_dict[\"points\"]\n",
    "#     all_axises = get_axis_for_nuclei(boundary_points)\n",
    "#     visualize_nuclei_axes(images[i], points, all_axises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9a8ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph_overlay_with_axes(image: np.ndarray, filtered_graph: nx.Graph, filtered_data_dict: dict[str, np.ndarray],\n",
    "                           node_size: int = 50, edge_width: float = 2.0,\n",
    "                           node_color: str = 'blue', edge_color: str = 'cyan',\n",
    "                           alpha: float = 0.5) -> None:\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # Display image\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    points = filtered_data_dict[\"points\"]\n",
    "    boundary_points = filtered_data_dict[\"coord\"]\n",
    "    axes = get_axis_for_nuclei(boundary_points)\n",
    "    \n",
    "    # Draw edges\n",
    "    for (n1, n2) in filtered_graph.edges():\n",
    "        pos1 = filtered_graph.nodes[n1]['pos']\n",
    "        pos2 = filtered_graph.nodes[n2]['pos']\n",
    "        ax.plot([pos1[1], pos2[1]], [pos1[0], pos2[0]], \n",
    "                color=edge_color, linewidth=edge_width, alpha=alpha)\n",
    "    \n",
    "    # Draw nodes\n",
    "    for node in filtered_graph.nodes():\n",
    "        pos = filtered_graph.nodes[node]['pos']\n",
    "        ax.scatter(pos[1], pos[0], s=node_size, c=node_color, \n",
    "                  edgecolors='black', linewidths=1, alpha=alpha, zorder=5)\n",
    "\n",
    "    # Draw axes\n",
    "    for point, axis in zip(points, axes):\n",
    "        start_point = point - axis * 25\n",
    "        end_point = point + axis * 25\n",
    "        \n",
    "        ax.plot([start_point[1], end_point[1]], \n",
    "               [start_point[0], end_point[0]],\n",
    "               color=\"red\", linewidth=2, alpha=alpha, zorder=4)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82436854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data_dict in enumerate(nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(masks[i], data_dict)\n",
    "#     points = filtered_data_dict[\"points\"]\n",
    "#     neighbor_dict, _ = get_delaunay_neighbors(points)\n",
    "#     boundary_points = filtered_data_dict[\"coord\"]\n",
    "#     dist_threshold = get_median_distance(points, neighbor_dict) * 1.5\n",
    "#     graph = build_neighbor_graph(points=points, neighbor_dict=neighbor_dict, boundary_points=boundary_points, distance_threshold=dist_threshold)\n",
    "#     filtered_graph = nx.subgraph_view(\n",
    "#         graph, \n",
    "#         filter_edge=lambda n1, n2: filter_neighbor_graph(\n",
    "#             graph, n1, n2, \n",
    "#             alignment_threshold=0.7, \n",
    "#             angle_threshold=45.0,\n",
    "#             distance_threshold=None\n",
    "#         )\n",
    "#     )\n",
    "#     visualize_graph_overlay_with_axes(images[i], filtered_graph, filtered_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3569bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data_dict in enumerate(nuclei_data_dicts):\n",
    "#     filtered_data_dict = filter_data_dict(masks[i], data_dict)\n",
    "#     points = filtered_data_dict[\"points\"]\n",
    "#     neighbor_dict, _ = get_delaunay_neighbors(points)\n",
    "#     boundary_points = filtered_data_dict[\"coord\"]\n",
    "#     dist_threshold = get_median_distance(points, neighbor_dict) * 1.5\n",
    "#     graph = build_neighbor_graph(points=points, neighbor_dict=neighbor_dict, boundary_points=boundary_points, distance_threshold=dist_threshold)\n",
    "#     filtered_graph = nx.subgraph_view(\n",
    "#         graph, \n",
    "#         filter_edge=lambda n1, n2: filter_neighbor_graph(\n",
    "#             graph, n1, n2, \n",
    "#             alignment_threshold=0.6, \n",
    "#             angle_threshold=45.0,\n",
    "#             distance_threshold=None\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(18, 12))\n",
    "\n",
    "\n",
    "#     all_axises = get_axis_for_nuclei(boundary_points)\n",
    "#     visualize_nuclei_axes(images[i], points, all_axises, ax=axes[0], line_length=25, point_size=10, linewidth=1.0)\n",
    "#     axes[0].set_title(\"Segmented Nuclei with Axes\")\n",
    "    \n",
    "#     visualize_nodes_by_similarity(images[i], filtered_graph, ax=axes[1], node_size=10)\n",
    "#     axes[1].set_title(\"Nuclei with Similarity\")\n",
    "\n",
    "#     visualize_graph_overlay(images[i], filtered_graph, ax=axes[2], node_size=10, edge_width=1.0)\n",
    "#     axes[2].set_title(\"Graph Overlay\")\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808d8a7",
   "metadata": {},
   "source": [
    "### Find unorganized regions with HDBClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "102e8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_unorganized_regions(data_dict: dict[str,any], distance_threshold: float = 0.4, min_samples_fraction: float = 0.01) -> dict[int, list]:\n",
    "    points = data_dict['points']\n",
    "    neighbor_dict, _ = get_delaunay_neighbors(points)\n",
    "    median_distance = get_median_distance(points, neighbor_dict)\n",
    "    num_points = len(points)\n",
    "    clusterer = DBSCAN(eps=distance_threshold * median_distance, min_samples=int(min_samples_fraction * num_points))\n",
    "    labels = clusterer.fit_predict(points)\n",
    "    clusters = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        clusters[label].append(points[i])\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "878524a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, data_dict, nuclei_mask in zip(images, nuclei_data_dicts, nuclei_masks):\n",
    "#     filtered_data_dict = filter_data_dict(nuclei_mask, data_dict)\n",
    "#     hdb_cluster = detect_unorganized_regions(filtered_data_dict)\n",
    "#     plt.figure(figsize=(18, 12))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(nuclei_mask)\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     for region_idx, (region_id, points) in enumerate(hdb_cluster.items()):\n",
    "#         points_array = np.array(points)\n",
    "#         plt.scatter(points_array[:, 1], points_array[:, 0], s=10, alpha=0.7, label=f'Region {region_id}')\n",
    "\n",
    "\n",
    "#     plt.title(f'Nuclei Clusters ({len(hdb_cluster)} regions)')\n",
    "#     #plt.legend(loc='upper right', fontsize=8)\n",
    "#     plt.imshow(image)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d78b8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_similarity(filtered_graph: nx.Graph) -> float:\n",
    "    similarities = []\n",
    "    for node in filtered_graph.nodes():\n",
    "        similarity = filtered_graph.nodes[node].get(\"best_similarity\", 0.0)\n",
    "        similarities.append(similarity)\n",
    "    return np.median(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a348023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classification(\n",
    "    image: np.ndarray, \n",
    "    filtered_graph: nx.Graph, \n",
    "    classifications: dict[int, str],\n",
    "    node_size: int = 50, \n",
    "    alpha: float = 0.7, \n",
    "    ax=None\n",
    ") -> None:\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        show_plot = True\n",
    "    else:\n",
    "        show_plot = False\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    organized_pos = []\n",
    "    unorganized_pos = []\n",
    "    \n",
    "    for node in filtered_graph.nodes():\n",
    "        pos = filtered_graph.nodes[node]['pos']\n",
    "        classification = classifications.get(node, 'unorganized')\n",
    "        \n",
    "        if classification == 'organized':\n",
    "            organized_pos.append([pos[0], pos[1]])\n",
    "        else:\n",
    "            unorganized_pos.append([pos[0], pos[1]])\n",
    "    \n",
    "    # Plot organized nuclei in green\n",
    "    if len(organized_pos) > 0:\n",
    "        organized_pos = np.array(organized_pos)\n",
    "        ax.scatter(organized_pos[:, 1], organized_pos[:, 0], \n",
    "                  s=node_size, c='green', alpha=alpha, \n",
    "                  label=f\"Organized\", zorder=5)\n",
    "    \n",
    "    # Plot unorganized nuclei in red\n",
    "    if len(unorganized_pos) > 0:\n",
    "        unorganized_pos = np.array(unorganized_pos)\n",
    "        ax.scatter(unorganized_pos[:, 1], unorganized_pos[:, 0], \n",
    "                  s=node_size, c='red', alpha=alpha, \n",
    "                  label=f\"Unorganized\", zorder=5)\n",
    "    \n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce18cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_nuclei_weighted(\n",
    "    filtered_graph: nx.Graph,\n",
    "    k_neighbors: int = 5,\n",
    "    use_second_order: bool = True,\n",
    "    threshold: float = None,\n",
    "    distance_weight: bool = True\n",
    ") -> dict[int, str]:\n",
    "    if threshold is None:\n",
    "        threshold = get_median_similarity(filtered_graph)\n",
    "    \n",
    "    classifications = {}\n",
    "    \n",
    "    for node in filtered_graph.nodes():\n",
    "        neighbors_with_dist = []\n",
    "        \n",
    "        for neighbor in filtered_graph.neighbors(node):\n",
    "            edge_data = filtered_graph[node][neighbor]\n",
    "            distance = edge_data.get('distance', 1.0)\n",
    "            neighbors_with_dist.append((neighbor, distance))\n",
    "        \n",
    "        neighbors_with_dist.sort(key=lambda x: x[1])\n",
    "        k_nearest = neighbors_with_dist[:k_neighbors]\n",
    "        \n",
    "        weighted_similarities = []\n",
    "        total_weight = 0.0\n",
    "        \n",
    "        for neighbor, distance in k_nearest:\n",
    "            sim = filtered_graph.nodes[neighbor].get('best_similarity', 0.0)\n",
    "            \n",
    "            if distance_weight and distance > 0:\n",
    "                # Weight by inverse distance\n",
    "                weight = 1.0 / (distance)\n",
    "            else:\n",
    "                weight = 1.0\n",
    "            \n",
    "            weighted_similarities.append(sim * weight)\n",
    "            total_weight += weight\n",
    "\n",
    "        if use_second_order and len(k_nearest) > 0:\n",
    "            second_order_neighbors = {}\n",
    "            \n",
    "            for neighbor, _ in k_nearest:\n",
    "                for second_neighbor in filtered_graph.neighbors(neighbor):\n",
    "                    if second_neighbor not in second_order_neighbors and second_neighbor != node:\n",
    "                        \n",
    "                        if second_neighbor not in [n for n, d in k_nearest]:\n",
    "                            try:\n",
    "                                edge_data = filtered_graph[neighbor][second_neighbor]\n",
    "                                dist = edge_data.get('distance', 1.0)\n",
    "                                second_order_neighbors[second_neighbor] = dist\n",
    "                            except:\n",
    "                                pass\n",
    "            \n",
    "            for neighbor, distance in second_order_neighbors.items():\n",
    "                sim = filtered_graph.nodes[neighbor].get('best_similarity', 0.0)\n",
    "                \n",
    "                # Reduce weight for second-order neighbors\n",
    "                if distance_weight and distance > 0:\n",
    "                    weight = 0.25 / (distance + 1e-6)\n",
    "                else:\n",
    "                    weight = 0.25\n",
    "                \n",
    "                weighted_similarities.append(sim * weight)\n",
    "                total_weight += weight\n",
    "        \n",
    "        if total_weight > 0:\n",
    "            avg_weighted_similarity = sum(weighted_similarities) / total_weight\n",
    "        else:\n",
    "            avg_weighted_similarity = filtered_graph.nodes[node].get('best_similarity', 0.0)\n",
    "        \n",
    "        if avg_weighted_similarity > threshold:\n",
    "            classifications[node] = \"organized\"\n",
    "        else:\n",
    "            classifications[node] = \"unorganized\"\n",
    "    \n",
    "    return classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9ca0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (image, data_dict, nuclei_mask) in enumerate(zip(images, nuclei_data_dicts, nuclei_masks)):\n",
    "#     filtered_data_dict = filter_data_dict(masks[i], data_dict)\n",
    "#     points = filtered_data_dict[\"points\"]\n",
    "#     neighbor_dict, _ = get_delaunay_neighbors(points)\n",
    "#     boundary_points = filtered_data_dict[\"coord\"]\n",
    "#     dist_threshold = get_median_distance(points, neighbor_dict) * 1.5\n",
    "#     graph = build_neighbor_graph(points=points, neighbor_dict=neighbor_dict, boundary_points=boundary_points, distance_threshold=dist_threshold)\n",
    "#     filtered_graph = nx.subgraph_view(\n",
    "#         graph, \n",
    "#         filter_edge=lambda n1, n2: filter_neighbor_graph(\n",
    "#             graph, n1, n2, \n",
    "#             alignment_threshold=0.6, \n",
    "#             angle_threshold=45.0,\n",
    "#             distance_threshold=None\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     classifications_weighted = classify_nuclei_weighted(\n",
    "#         filtered_graph=filtered_graph,\n",
    "#         k_neighbors=5,\n",
    "#         use_second_order=True,\n",
    "#         threshold=None,\n",
    "#         distance_weight=True\n",
    "#     )\n",
    "#     visualize_classification(image, filtered_graph, classifications_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada7950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
