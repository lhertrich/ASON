{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b3e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2b319",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248991f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bioimageio_utils.py (2): pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "|2026-01-03|19:35:31.085| [WARNING] auto.py (21): IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "objc[45845]: Class GNotificationCenterDelegate is implemented in both /opt/anaconda3/envs/research_project/lib/libgio-2.0.0.dylib (0x31ae386d8) and /opt/anaconda3/envs/research_project/lib/python3.12/site-packages/openslide_bin/libopenslide.1.dylib (0x377ad9318). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "|2026-01-03|19:35:40.548| [WARNING] __init__.py (24): A new version of Albumentations is available: 2.0.8 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from histomicstk.preprocessing.color_normalization import (\n",
    "    deconvolution_based_normalization,\n",
    ")\n",
    "from histomicstk.saliency.tissue_detection import get_tissue_mask\n",
    "from skimage.transform import resize\n",
    "from skimage.exposure import rescale_intensity\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "from tiatoolbox.tools import stainnorm\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db3c0e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358d5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(\n",
    "    [\n",
    "        project_root / \"data/images\" / path\n",
    "        for path in os.listdir(project_root / \"data/images\")\n",
    "        if not path.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "images = list(map(tifffile.imread, image_paths))\n",
    "\n",
    "normalized_image_paths = sorted(\n",
    "    [\n",
    "        project_root / \"data/normalized_images\" / path\n",
    "        for path in os.listdir(project_root / \"data/normalized_images\")\n",
    "        if not path.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "normalized_images = list(map(tifffile.imread, normalized_image_paths))\n",
    "\n",
    "mask_paths = sorted(\n",
    "    [\n",
    "        project_root / \"data/masks\" / path\n",
    "        for path in os.listdir(project_root / \"data/masks\")\n",
    "        if not path.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "masks = list(map(tifffile.imread, mask_paths))\n",
    "data = list(zip(images, masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acb95f",
   "metadata": {},
   "source": [
    "# Find Reference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3186bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_histogram_separation(\n",
    "    image: np.ndarray, mask: np.ndarray, model: StarDist2D\n",
    ") -> float:\n",
    "\n",
    "    image_normed = rescale_intensity(image, out_range=(0, 1))\n",
    "    labels, data_dict = model.predict_instances(\n",
    "        image_normed, axes=\"YXC\", prob_thresh=0.05, nms_thresh=0.3, return_labels=True\n",
    "    )\n",
    "\n",
    "    nuclei_mask = labels > 0\n",
    "    tissue_mask = mask & ~nuclei_mask\n",
    "\n",
    "    nuclei_intensities = image[nuclei_mask]\n",
    "    tissue_intensities = image[tissue_mask]\n",
    "\n",
    "    if len(nuclei_intensities) < 100 or len(tissue_intensities) < 100:\n",
    "        return 0.0\n",
    "\n",
    "    mean_nuclei = np.mean(nuclei_intensities)\n",
    "    mean_tissue = np.mean(tissue_intensities)\n",
    "    std_nuclei = np.std(nuclei_intensities)\n",
    "    std_tissue = np.std(tissue_intensities)\n",
    "\n",
    "    # Use between-class variance\n",
    "    w_nuclei = len(nuclei_intensities) / (\n",
    "        len(nuclei_intensities) + len(tissue_intensities)\n",
    "    )\n",
    "    w_tissue = 1 - w_nuclei\n",
    "\n",
    "    separation_score = w_nuclei * w_tissue * (mean_nuclei - mean_tissue) ** 2\n",
    "\n",
    "    return separation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ff045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reference_image(\n",
    "    data: List[Tuple[np.ndarray, np.ndarray]], model: StarDist2D\n",
    ") -> Tuple[int, np.ndarray]:\n",
    "\n",
    "    print(\"Analyzing histogram separation for all images...\")\n",
    "\n",
    "    max_separation_score = 0\n",
    "    reference_idx = 0\n",
    "    reference_image = images[0]\n",
    "\n",
    "    for i, (image, mask) in enumerate(data):\n",
    "        separation_score = calculate_histogram_separation(image, mask, model)\n",
    "        if separation_score > max_separation_score:\n",
    "            max_separation_score = separation_score\n",
    "            reference_idx = i\n",
    "            reference_image = image\n",
    "\n",
    "    print(\n",
    "        f\"\\nReference image selected: Image {reference_idx} with score {max_separation_score:.4f}\"\n",
    "    )\n",
    "\n",
    "    return reference_idx, reference_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844bbe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_he' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.692478, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "model = StarDist2D.from_pretrained(\"2D_versatile_he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "707fc830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing histogram separation for all images...\n",
      "\n",
      "Reference image selected: Image 9 with score 634.4435\n"
     ]
    }
   ],
   "source": [
    "ref_idx, ref_img = find_reference_image(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8cd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(ref_img)\n",
    "# plt.axis(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d11e2c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/levin/Documents/Uni/Master/semester_3/research_project/ASON/data/images/E2+P4+DHT_1_M7_3L_0013.tif')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_path = image_paths[ref_idx]\n",
    "ref_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a47460",
   "metadata": {},
   "source": [
    "# Test Macenko and Vahadane Normalization with Reference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7a61711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2025-12-28|13:03:00.241| [WARNING] Vahadane stain extraction/normalization algorithms are unstable after the update to `dictionary learning` algorithm in scikit-learn > v0.23.0 (see issue #382). Please be advised and consider using other stain extraction (normalization) algorithms.\n"
     ]
    }
   ],
   "source": [
    "vah_norm = stainnorm.VahadaneNormalizer()\n",
    "vah_norm.fit(ref_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b692bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_norm = stainnorm.MacenkoNormalizer()\n",
    "mac_norm.fit(ref_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "684ba0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in images:\n",
    "#     img_norm_vah = vah_norm.transform(img.copy())\n",
    "#     img_norm_mac = mac_norm.transform(img.copy())\n",
    "#     compare_two_images(img, img_norm_vah, \"Original Image\", \"Vahadane Normalized Image\")\n",
    "#     compare_two_images(img, img_norm_mac, \"Original Image\", \"Macenko Normalized Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3a4b1",
   "metadata": {},
   "source": [
    "# Test Macenko Normalization for Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d1c70283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, mask in data:\n",
    "#     image_norm = mac_norm.transform(image.copy())\n",
    "#     image_resc = rescale_intensity(image, out_range=(0, 1))\n",
    "#     image_norm_resc = rescale_intensity(image_norm, out_range=(0, 1))\n",
    "#     labels, _ = model.predict_instances(image_resc, axes='YXC', prob_thresh=0.05, nms_thresh=0.3, return_labels=True)\n",
    "#     labels_norm, _ = model.predict_instances(image_norm_resc, axes='YXC', prob_thresh=0.05, nms_thresh=0.3, return_labels=True)\n",
    "#     labels = cut_out_image(labels, mask)\n",
    "#     labels_norm = cut_out_image(labels_norm, mask)\n",
    "#     compare_two_images(render_label(labels, img=image_resc, cmap=(1.0, 1.0, 0), alpha=0.6), render_label(labels_norm, img=image_norm_resc, cmap=(1.0, 1.0, 0), alpha=0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b9f36",
   "metadata": {},
   "source": [
    "Macenko normalization does not improve the segmentation quality, in some cases it even reduces the performance. For now, do not apply macenko normalization but continue with the original images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f46708",
   "metadata": {},
   "source": [
    "# Test Reinhard Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2dcb51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reinhard_norm = stainnorm.ReinhardNormalizer()\n",
    "reinhard_norm.fit(ref_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5fcfa6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in images:\n",
    "#     img_norm = reinhard_norm.transform(img.copy())\n",
    "#     compare_two_images(img, img_norm, \"Original Image\", \"Reinhard Normalized Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "300180b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_norm_num_objects = []\n",
    "# norm_num_objects = []\n",
    "\n",
    "# for image, mask in data:\n",
    "#     image_norm = reinhard_norm.transform(image.copy())\n",
    "#     image_resc = rescale_intensity(image, out_range=(0, 1))\n",
    "#     image_norm_resc = rescale_intensity(image_norm, out_range=(0, 1))\n",
    "#     labels, seg_dict = model.predict_instances(image_resc, axes='YXC', prob_thresh=0.05, nms_thresh=0.3, return_labels=True)\n",
    "#     labels_norm, seg_dict_norm = model.predict_instances(image_norm_resc, axes='YXC', prob_thresh=0.05, nms_thresh=0.3, return_labels=True)\n",
    "#     labels = cut_out_image(labels, mask)\n",
    "#     labels_norm = cut_out_image(labels_norm, mask)\n",
    "#     non_norm_num_objects.append(len(seg_dict['prob']))\n",
    "#     norm_num_objects.append(len(seg_dict_norm['prob']))\n",
    "#     compare_two_images(render_label(labels, img=image_resc, cmap=(1.0, 1.0, 0), alpha=0.6), render_label(labels_norm, img=image_norm_resc, cmap=(1.0, 1.0, 0), alpha=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a06db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of detected nuclei in non-normalized images: 1005.85\n",
      "Average number of detected nuclei in normalized images: 1179.6\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Average number of detected nuclei in non-normalized images: {np.mean(non_norm_num_objects)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Average number of detected nuclei in normalized images: {np.mean(norm_num_objects)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0734d",
   "metadata": {},
   "source": [
    "Reihnard Normalization is overshooting the colors and contrast as well, so continue without normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754dc09",
   "metadata": {},
   "source": [
    "# --- OLD NORMALIZATION EXPERIMENTS ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4150c3c",
   "metadata": {},
   "source": [
    "### Test Reference Image 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for visualization in presentation\n",
    "\n",
    "# for i, img in enumerate(images):\n",
    "#     img_norm_vah = stain_normalizer_2.transform(img.copy())\n",
    "#     img_norm_mac = normalized_images[i]\n",
    "#     plt.figure(figsize=(18, 6))\n",
    "\n",
    "#     plt.subplot(1, 3, 1)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Original Image\")\n",
    "#     plt.imshow(img, cmap='gray')\n",
    "\n",
    "#     plt.subplot(1, 3, 2)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Macenko Normalized Image\")\n",
    "#     plt.imshow(img_norm_mac)\n",
    "\n",
    "#     plt.subplot(1, 3, 3)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Vahadane Normalized Image\")\n",
    "#     plt.imshow(img_norm_vah)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "300099f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in images:\n",
    "#     img_norm = stain_normalizer_1.transform(img.copy())\n",
    "#     compare_two_images(img, img_norm, \"Original Image\", \"Normalized Image (Ref1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118a414",
   "metadata": {},
   "source": [
    "##### Compare segmentation performance with non-normalized and Ref1-normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77ce5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stardist.models import StarDist2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe5f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_he' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.692478, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "model = StarDist2D.from_pretrained(\"2D_versatile_he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c0c6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = sorted(\n",
    "    [\n",
    "        \"data/masks/\" + path\n",
    "        for path in os.listdir(\"data/masks\")\n",
    "        if not path.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "masks = list(map(tifffile.imread, mask_paths))\n",
    "data = list(zip(images, masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13c74145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, mask in data:\n",
    "#     image_norm = stain_normalizer_1.transform(image.copy())\n",
    "#     image_resc = rescale_intensity(image, out_range=(0, 1))\n",
    "#     image_norm_resc = rescale_intensity(image_norm, out_range=(0, 1))\n",
    "#     labels, _ = model.predict_instances(image_resc, axes='YXC', prob_thresh=0.05, nms_thresh=0.3, return_labels=True)\n",
    "#     labels_norm, _ = model.predict_instances(image_norm_resc, axes='YXC', prob_thresh=0.05, nms_thresh=0.3, return_labels=True)\n",
    "#     labels = cut_out_image(labels, mask)\n",
    "#     labels_norm = cut_out_image(labels_norm, mask)\n",
    "#     compare_two_images(render_label(labels, img=image_resc, cmap=(1.0, 1.0, 0), alpha=0.6), render_label(labels_norm, img=image_norm_resc, cmap=(1.0, 1.0, 0), alpha=0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904200b",
   "metadata": {},
   "source": [
    "### Test Reference Image 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "445ff0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in images:\n",
    "#     img_norm = stain_normalizer_2.transform(img.copy())\n",
    "#     compare_two_images(img, img_norm, \"Original Image\", \"Normalized Image (Ref2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aafb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, mask in data:\n",
    "#     image_norm = stain_normalizer_2.transform(image.copy())\n",
    "#     image_resc = rescale_intensity(image, out_range=(0, 1))\n",
    "#     image_norm_resc = rescale_intensity(image_norm, out_range=(0, 1))\n",
    "#     labels, _ = model.predict_instances(image_resc, axes='YXC', prob_thresh=0.05, nms_thresh=0.3, return_labels=True)\n",
    "#     labels_norm, _ = model.predict_instances(image_norm_resc, axes='YXC', prob_thresh=0.05, nms_thresh=0.3, return_labels=True)\n",
    "#     labels = cut_out_image(labels, mask)\n",
    "#     labels_norm = cut_out_image(labels_norm, mask)\n",
    "#     compare_two_images(render_label(labels, img=image_resc, cmap=(1.0, 1.0, 0), alpha=0.6), render_label(labels_norm, img=image_norm_resc, cmap=(1.0, 1.0, 0), alpha=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d851024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(img):\n",
    "    mask_out, _ = get_tissue_mask(\n",
    "        img, deconvolve_first=True, n_thresholding_steps=1, sigma=1.5, min_size=30\n",
    "    )\n",
    "\n",
    "    mask_out_fixed = (\n",
    "        resize(mask_out == 0, output_shape=img.shape[:2], order=0, preserve_range=True)\n",
    "        == 1\n",
    "    )\n",
    "\n",
    "    return ~mask_out_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e632e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_mask_1 = create_mask(reference_image_1)\n",
    "reference_mask_2 = create_mask(reference_image_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "beea6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut_out_reference_1 = cut_out_image(reference_image_1, reference_mask_1)\n",
    "# cut_out_reference_2 = cut_out_image(reference_image_2, reference_mask_2)\n",
    "# compare_two_images(cut_out_reference_1, cut_out_reference_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "533635cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_normalization_macenko(\n",
    "    target_img,\n",
    "    reference_img,\n",
    "    mask=None,\n",
    "    stains=[\"hematoxylin\", \"eosin\"],\n",
    "    stain_unmixing_method=\"macenko_pca\",\n",
    "):\n",
    "    stain_unmixing_routine_params = {\n",
    "        \"stains\": stains,\n",
    "        \"stain_unmixing_method\": stain_unmixing_method,\n",
    "    }\n",
    "\n",
    "    normalized_target_img = deconvolution_based_normalization(\n",
    "        target_img,\n",
    "        im_target=reference_img,\n",
    "        mask_out=mask,\n",
    "        stain_unmixing_routine_params=stain_unmixing_routine_params,\n",
    "    )\n",
    "\n",
    "    return normalized_target_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1178e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [create_mask(img) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f1a0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_two_images(images[5], masks[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b655b",
   "metadata": {},
   "source": [
    "### Test Reference Image 1 without cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66f9e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images_1 = [\n",
    "    color_normalization_macenko(image, reference_image_1, masks[i])\n",
    "    for i, image in enumerate(images)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6488c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, norm_img in zip(images, normalized_images_1):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Original image\")\n",
    "#     plt.imshow(img)\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Normalized image\")\n",
    "#     plt.imshow(norm_img)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf66b9",
   "metadata": {},
   "source": [
    "### Test reference image 2 without cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16517bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images_2 = [\n",
    "    color_normalization_macenko(image, reference_image_2, masks[i])\n",
    "    for i, image in enumerate(images)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6d75d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, norm_img in zip(images, normalized_images_2):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Original image\")\n",
    "#     plt.imshow(img)\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Normalized image\")\n",
    "#     plt.imshow(norm_img)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5d1d5",
   "metadata": {},
   "source": [
    "### Test reference image 1 with cut out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9af1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images_1_cut = [\n",
    "    color_normalization_macenko(image, cut_out_reference_1, masks[i])\n",
    "    for i, image in enumerate(images)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64be2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, norm_img in zip(images, normalized_images_1_cut):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Original image\")\n",
    "#     plt.imshow(img)\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Normalized image\")\n",
    "#     plt.imshow(norm_img)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5707a",
   "metadata": {},
   "source": [
    "### Test reference 2 with cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d223398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images_2_cut = [\n",
    "    color_normalization_macenko(image, cut_out_reference_2, masks[i])\n",
    "    for i, image in enumerate(images)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3efa4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, norm_img in zip(images, normalized_images_2_cut):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Original image\")\n",
    "#     plt.imshow(img)\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.axis(False)\n",
    "#     plt.title(\"Normalized image\")\n",
    "#     plt.imshow(norm_img)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793dfdc",
   "metadata": {},
   "source": [
    "Reference image 2 without cutout seems to provide the best results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b949db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
