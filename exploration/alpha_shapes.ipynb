{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1735ab23",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook explores the usage of alpha shapes to detect layers.\n",
    "Therefore, it performs multiple steps:\n",
    "1. Segment tissue with a trained model\n",
    "2. Segment nuclei using StarDist\n",
    "3. Create an overlay of the nuclei and the tissue\n",
    "4. Calculate relative size of nuclei to detected tissue\n",
    "5. Apply delauney triangulation on nuclei\n",
    "6. Apply alpha shapes with relative threshold depending on nuclei and tissue size (avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ffd5f5",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799128da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91512d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial import Delaunay\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc182207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load four images, which present a good example of layers\n",
    "LAYER_PATH = project_root / \"data/layer_examples\"\n",
    "\n",
    "paths = [(LAYER_PATH / image_path) for image_path in os.listdir(LAYER_PATH)]\n",
    "images = list(map(tifffile.imread, paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df12ad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2025-12-12|15:21:12.592| [WARNING] /opt/anaconda3/envs/research_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "objc[5369]: Class GNotificationCenterDelegate is implemented in both /opt/anaconda3/envs/research_project/lib/libgio-2.0.0.dylib (0x36d78c6d8) and /opt/anaconda3/envs/research_project/lib/python3.12/site-packages/openslide_bin/libopenslide.1.dylib (0x377095318). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "|2025-12-12|15:21:32.780| [WARNING] /opt/anaconda3/envs/research_project/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize images\n",
    "from src.utils.reinhard_normalizer import ReinhardNormalizer\n",
    "\n",
    "normalizer = ReinhardNormalizer()\n",
    "images = [normalizer.normalize(img) for img in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6c2953",
   "metadata": {},
   "source": [
    "## 1. Segment tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86149bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from src.models.model_loader import ModelLoader\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620b4090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CNN: unet_2c\n"
     ]
    }
   ],
   "source": [
    "# Specify model to load\n",
    "model_loader = ModelLoader()\n",
    "MODEL_CFG = \"unet_2\"\n",
    "model = model_loader.load_cnn_model(MODEL_CFG, \"unet_2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6dab148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessing import inference_processing\n",
    "from skimage.transform import resize\n",
    "ORG_RES = (1920, 2560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e41807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "masks = []\n",
    "labeled_tissues = []\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "print(device)\n",
    "for img in images:\n",
    "    img = inference_processing(img, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_logits = model(img)\n",
    "        pred_mask = torch.argmax(pred_logits, dim=1).squeeze()\n",
    "        pred_mask = pred_mask.cpu().numpy()\n",
    "        pred_mask = resize(pred_mask, ORG_RES, anti_aliasing=True)\n",
    "    labeled_tissue = label(pred_mask > 0, connectivity=2)\n",
    "    labeled_tissues.append(labeled_tissue)\n",
    "    masks.append(pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3057248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.helpers import compare_two_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e1a9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, mask in zip(images, masks):\n",
    "#     compare_two_images(img, mask, \"Normalized Image\", \"Predicted Mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72469c",
   "metadata": {},
   "source": [
    "### 1 b Try to apply Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba12b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "def separate_touching_regions(binary_mask, min_distance=20, footprint_size=25):\n",
    "    \"\"\"Separate touching regions using watershed on distance transform.\"\"\"\n",
    "    distance = ndimage.distance_transform_edt(binary_mask)\n",
    "    \n",
    "    # Find local maxima in distance transform (these become markers/seeds)\n",
    "    # Each \"core\" of a tissue region will have a local maximum\n",
    "    coords = peak_local_max(\n",
    "        distance, \n",
    "        min_distance=min_distance,  # Minimum distance between peaks\n",
    "        footprint=np.ones((footprint_size, footprint_size)),\n",
    "        labels=binary_mask\n",
    "    )\n",
    "    \n",
    "    # Create markers from the peaks\n",
    "    markers = np.zeros(distance.shape, dtype=int)\n",
    "    markers[tuple(coords.T)] = np.arange(1, len(coords) + 1)\n",
    "    markers = ndimage.label(markers)[0]\n",
    "    \n",
    "    # Apply watershed - negative distance so \"valleys\" become the separation lines\n",
    "    labels = watershed(-distance, markers, mask=binary_mask)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307b14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_masks = [(mask > 0).astype(int) for mask in masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa901444",
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_masks = [separate_touching_regions(mask) for mask in binary_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57f71f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, mask in zip(images, watershed_masks):\n",
    "#     compare_two_images(img, mask, \"Normalized Image\", \"Predicted Mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bfd70a",
   "metadata": {},
   "source": [
    "### 1c Try to apply Morphological Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b0bdf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_opening, binary_closing, disk\n",
    "from skimage.measure import label\n",
    "\n",
    "def separate_with_morphology(binary_mask, open_radius=10, close_radius=3):\n",
    "    \"\"\"\n",
    "    Separate touching regions using morphological operations.\n",
    "    \n",
    "    Parameters:\n",
    "    - open_radius: Larger = more aggressive separation (breaks thicker connections)\n",
    "    - close_radius: Fills small holes created by opening\n",
    "    \"\"\"\n",
    "    # Opening: erosion then dilation - breaks thin connections\n",
    "    opened = binary_opening(binary_mask, disk(open_radius))\n",
    "    \n",
    "    # Closing: dilation then erosion - fills small holes\n",
    "    closed = binary_closing(opened, disk(close_radius))\n",
    "    \n",
    "    # Label the separated regions\n",
    "    labeled = label(closed, connectivity=2)\n",
    "    \n",
    "    return labeled, closed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "487f34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_masks = [separate_with_morphology(mask)[1] for mask in masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5996aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, mask in zip(images, morph_masks):\n",
    "#     compare_two_images(img, mask, \"Normalized Image\", \"Cleaned Mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3680a7cb",
   "metadata": {},
   "source": [
    "## 2. Segment Nuclei with Stardist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee3c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2025-12-12|15:21:44.388| [WARNING] bioimageio_utils.py (2): pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from stardist.models import StarDist2D\n",
    "from stardist.plot import render_label\n",
    "from src.utils.helpers import cut_out_image\n",
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0864359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_he' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.692478, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "stardist_model = StarDist2D.from_pretrained(\"2D_versatile_he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3b554bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_masks = []\n",
    "nuclei_data_dicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5807dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in zip(images, masks):\n",
    "    image_normed = rescale_intensity(img, out_range=(0, 1))\n",
    "    labels, data_dict = stardist_model.predict_instances(image_normed, axes='YXC', prob_thresh=0.6, nms_thresh=0.0, return_labels=True)\n",
    "    filtered_labels = cut_out_image(labels, mask)\n",
    "    binary_labels = (filtered_labels > 0).astype(np.uint8)\n",
    "    nuclei_masks.append(binary_labels)\n",
    "    nuclei_data_dicts.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "726a129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, mask in zip(images, nuclei_masks):\n",
    "#     compare_two_images(img, mask, \"Normalized Image\", \"Filtered nuclei mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eefe64",
   "metadata": {},
   "source": [
    "## 3. Create overlay of mask and nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a765a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_masks(tissue_mask, nuclei_mask):\n",
    "    \"\"\"\n",
    "    Combines tissue and nuclei masks into a single mask.\n",
    "    \n",
    "    Args:\n",
    "        tissue_mask: Binary tissue mask (H, W), values 0 or 1\n",
    "        nuclei_mask: Binary nuclei mask (H, W), values 0 or 1\n",
    "    \n",
    "    Returns:\n",
    "        combined_mask: Single mask with values:\n",
    "            0 = background\n",
    "            1 = tissue (without nuclei)\n",
    "            2 = nuclei\n",
    "    \"\"\"\n",
    "    combined_mask = np.zeros_like(tissue_mask, dtype=np.uint8)\n",
    "    \n",
    "    combined_mask[tissue_mask > 0] = 1\n",
    "    \n",
    "    combined_mask[nuclei_mask > 0] = 2\n",
    "    \n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9000fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_masks = [combine_masks(tissue_mask, nuclei_mask) for tissue_mask, nuclei_mask in zip(masks, nuclei_masks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11850339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "# for image, combined_mask in zip(images, combined_masks):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(\"Normalized image\")\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     colors = ['black', 'white', 'blue']\n",
    "#     cmap = ListedColormap(colors)\n",
    "#     plt.imshow(combined_mask, cmap=cmap, vmin=0, vmax=2)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(\"Tissue and nuclei mask\")\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eac6e5",
   "metadata": {},
   "source": [
    "## 4. Calculate relative size of nuclei compared to detected tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61d68029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e9907a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_from_combined(combined_mask: np.ndarray) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate metrics from a combined mask, including average sizes of individual regions.\n",
    "    \n",
    "    Args:\n",
    "        combined_mask (np.ndarray): Mask with values 0 (background), 1 (tissue), 2 (nuclei)\n",
    "    \n",
    "    Returns:\n",
    "        result(dict): dict with metrics\n",
    "    \"\"\"\n",
    "    total_pixels = combined_mask.size\n",
    "    background_pixels = np.sum(combined_mask == 0)\n",
    "    tissue_pixels = np.sum(combined_mask == 1)\n",
    "    nuclei_pixels = np.sum(combined_mask == 2)\n",
    "    \n",
    "    total_tissue_pixels = tissue_pixels + nuclei_pixels\n",
    "    \n",
    "    tissue_percentage = (tissue_pixels / total_pixels) * 100\n",
    "    nuclei_percentage = (nuclei_pixels / total_pixels) * 100\n",
    "    total_tissue_percentage = (total_tissue_pixels / total_pixels) * 100\n",
    "    \n",
    "    nuclei_to_tissue_ratio = (nuclei_pixels / total_tissue_pixels * 100) if total_tissue_pixels > 0 else 0\n",
    "    \n",
    "    nuclei_binary = (combined_mask == 2).astype(np.uint8)\n",
    "    nuclei_labeled = label(nuclei_binary, connectivity=2)\n",
    "    nuclei_regions = regionprops(nuclei_labeled)\n",
    "    \n",
    "    nuclei_sizes = [region.area for region in nuclei_regions]\n",
    "    num_nuclei = len(nuclei_sizes)\n",
    "    avg_nuclei_size = np.mean(nuclei_sizes) if nuclei_sizes else 0\n",
    "    median_nuclei_size = np.median(nuclei_sizes) if nuclei_sizes else 0\n",
    "    std_nuclei_size = np.std(nuclei_sizes) if nuclei_sizes else 0\n",
    "    \n",
    "    tissue_binary = (combined_mask > 0).astype(np.uint8)\n",
    "    tissue_labeled = label(tissue_binary, connectivity=2)\n",
    "    tissue_regions = regionprops(tissue_labeled)\n",
    "    \n",
    "    tissue_sizes = [region.area for region in tissue_regions]\n",
    "    num_tissue_regions = len(tissue_sizes)\n",
    "    avg_tissue_size = np.mean(tissue_sizes) if tissue_sizes else 0\n",
    "    median_tissue_size = np.median(tissue_sizes) if tissue_sizes else 0\n",
    "    std_tissue_size = np.std(tissue_sizes) if tissue_sizes else 0\n",
    "    \n",
    "    # Ratio of average sizes\n",
    "    avg_size_ratio = (avg_nuclei_size / avg_tissue_size) if avg_tissue_size > 0 else 0\n",
    "    \n",
    "    result = {\n",
    "        # Number of pixels\n",
    "        'background_pixels': background_pixels,\n",
    "        'tissue_only_pixels': tissue_pixels,\n",
    "        'nuclei_pixels': nuclei_pixels,\n",
    "        'total_tissue_pixels': total_tissue_pixels,\n",
    "        'tissue_only_percentage': tissue_percentage,\n",
    "        'nuclei_percentage': nuclei_percentage,\n",
    "        'total_tissue_percentage': total_tissue_percentage,\n",
    "        'nuclei_to_tissue_ratio': nuclei_to_tissue_ratio,\n",
    "        \n",
    "        # Size metrics\n",
    "        'num_nuclei': num_nuclei,\n",
    "        'avg_nuclei_size': avg_nuclei_size,\n",
    "        'median_nuclei_size': median_nuclei_size,\n",
    "        'std_nuclei_size': std_nuclei_size,\n",
    "        'min_nuclei_size': min(nuclei_sizes) if nuclei_sizes else 0,\n",
    "        'max_nuclei_size': max(nuclei_sizes) if nuclei_sizes else 0,\n",
    "        \n",
    "        'num_tissue_regions': num_tissue_regions,\n",
    "        'avg_tissue_region_size': avg_tissue_size,\n",
    "        'median_tissue_region_size': median_tissue_size,\n",
    "        'std_tissue_region_size': std_tissue_size,\n",
    "        'min_tissue_region_size': min(tissue_sizes) if tissue_sizes else 0,\n",
    "        'max_tissue_region_size': max(tissue_sizes) if tissue_sizes else 0,\n",
    "        \n",
    "        'avg_nuclei_to_tissue_size_ratio': avg_size_ratio,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "metrics_list = []\n",
    "for idx, combined in enumerate(combined_masks):\n",
    "    metrics = calculate_metrics_from_combined(combined)\n",
    "    metrics['image_id'] = idx\n",
    "    metrics_list.append(metrics)\n",
    "\n",
    "df = pd.DataFrame(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5790c42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>background_pixels</th>\n",
       "      <th>tissue_only_pixels</th>\n",
       "      <th>nuclei_pixels</th>\n",
       "      <th>total_tissue_pixels</th>\n",
       "      <th>tissue_only_percentage</th>\n",
       "      <th>nuclei_percentage</th>\n",
       "      <th>total_tissue_percentage</th>\n",
       "      <th>nuclei_to_tissue_ratio</th>\n",
       "      <th>num_nuclei</th>\n",
       "      <th>avg_nuclei_size</th>\n",
       "      <th>...</th>\n",
       "      <th>min_nuclei_size</th>\n",
       "      <th>max_nuclei_size</th>\n",
       "      <th>num_tissue_regions</th>\n",
       "      <th>avg_tissue_region_size</th>\n",
       "      <th>median_tissue_region_size</th>\n",
       "      <th>std_tissue_region_size</th>\n",
       "      <th>min_tissue_region_size</th>\n",
       "      <th>max_tissue_region_size</th>\n",
       "      <th>avg_nuclei_to_tissue_size_ratio</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2194476</td>\n",
       "      <td>2251316</td>\n",
       "      <td>469408</td>\n",
       "      <td>2720724</td>\n",
       "      <td>45.803141</td>\n",
       "      <td>9.550130</td>\n",
       "      <td>55.353271</td>\n",
       "      <td>17.253055</td>\n",
       "      <td>997</td>\n",
       "      <td>470.820461</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>21</td>\n",
       "      <td>129558.285714</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>330071.025250</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1466285.0</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4099652</td>\n",
       "      <td>664371</td>\n",
       "      <td>151177</td>\n",
       "      <td>815548</td>\n",
       "      <td>13.516663</td>\n",
       "      <td>3.075704</td>\n",
       "      <td>16.592367</td>\n",
       "      <td>18.536861</td>\n",
       "      <td>245</td>\n",
       "      <td>617.048980</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>18</td>\n",
       "      <td>45308.222222</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>121953.464164</td>\n",
       "      <td>72.0</td>\n",
       "      <td>536825.0</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4125262</td>\n",
       "      <td>631641</td>\n",
       "      <td>158297</td>\n",
       "      <td>789938</td>\n",
       "      <td>12.850769</td>\n",
       "      <td>3.220561</td>\n",
       "      <td>16.071330</td>\n",
       "      <td>20.039168</td>\n",
       "      <td>276</td>\n",
       "      <td>573.539855</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>7</td>\n",
       "      <td>112848.285714</td>\n",
       "      <td>8322.0</td>\n",
       "      <td>190278.909224</td>\n",
       "      <td>126.0</td>\n",
       "      <td>541178.0</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2687775</td>\n",
       "      <td>1956668</td>\n",
       "      <td>270757</td>\n",
       "      <td>2227425</td>\n",
       "      <td>39.808512</td>\n",
       "      <td>5.508565</td>\n",
       "      <td>45.317078</td>\n",
       "      <td>12.155606</td>\n",
       "      <td>696</td>\n",
       "      <td>389.018678</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>4</td>\n",
       "      <td>556856.250000</td>\n",
       "      <td>5328.5</td>\n",
       "      <td>958342.753269</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2216738.0</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   background_pixels  tissue_only_pixels  nuclei_pixels  total_tissue_pixels  \\\n",
       "0            2194476             2251316         469408              2720724   \n",
       "1            4099652              664371         151177               815548   \n",
       "2            4125262              631641         158297               789938   \n",
       "3            2687775             1956668         270757              2227425   \n",
       "\n",
       "   tissue_only_percentage  nuclei_percentage  total_tissue_percentage  \\\n",
       "0               45.803141           9.550130                55.353271   \n",
       "1               13.516663           3.075704                16.592367   \n",
       "2               12.850769           3.220561                16.071330   \n",
       "3               39.808512           5.508565                45.317078   \n",
       "\n",
       "   nuclei_to_tissue_ratio  num_nuclei  avg_nuclei_size  ...  min_nuclei_size  \\\n",
       "0               17.253055         997       470.820461  ...              9.0   \n",
       "1               18.536861         245       617.048980  ...              1.0   \n",
       "2               20.039168         276       573.539855  ...              5.0   \n",
       "3               12.155606         696       389.018678  ...             87.0   \n",
       "\n",
       "   max_nuclei_size  num_tissue_regions  avg_tissue_region_size  \\\n",
       "0           1772.0                  21           129558.285714   \n",
       "1           1639.0                  18            45308.222222   \n",
       "2           1404.0                   7           112848.285714   \n",
       "3           1556.0                   4           556856.250000   \n",
       "\n",
       "   median_tissue_region_size  std_tissue_region_size  min_tissue_region_size  \\\n",
       "0                     1273.0           330071.025250                    63.0   \n",
       "1                     2966.0           121953.464164                    72.0   \n",
       "2                     8322.0           190278.909224                   126.0   \n",
       "3                     5328.5           958342.753269                    30.0   \n",
       "\n",
       "   max_tissue_region_size  avg_nuclei_to_tissue_size_ratio  image_id  \n",
       "0               1466285.0                         0.003634         0  \n",
       "1                536825.0                         0.013619         1  \n",
       "2                541178.0                         0.005082         2  \n",
       "3               2216738.0                         0.000699         3  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a357b6c",
   "metadata": {},
   "source": [
    "## 5. Apply Alpha Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16708444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clusters\n",
    "cluster_list = []\n",
    "\n",
    "for tissue_labeled, data_dict in zip(labeled_tissues, nuclei_data_dicts):\n",
    "    clusters = {}\n",
    "\n",
    "    nucleus_centers = data_dict['points']\n",
    "\n",
    "    for idx, (x, y) in enumerate(nucleus_centers):\n",
    "        x_int, y_int = int(x), int(y)\n",
    "        \n",
    "        # Check bounds\n",
    "        if 0 <= x_int < tissue_labeled.shape[0] and 0 <= y_int < tissue_labeled.shape[1]:\n",
    "            region_id = tissue_labeled[x_int, y_int]\n",
    "            \n",
    "            if region_id == 0:\n",
    "                continue\n",
    "            \n",
    "            if region_id not in clusters:\n",
    "                clusters[region_id] = []\n",
    "            \n",
    "            clusters[region_id].append((x, y))\n",
    "    cluster_list.append(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c77a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2025-12-12|15:21:53.323| [WARNING] network.py (59): pyproj unable to set PROJ database path.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import alphashape\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import numpy as np\n",
    "\n",
    "def extract_layer(points, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Extract the outermost layer of points using alpha shapes.\n",
    "    \n",
    "    Args:\n",
    "        points: List of (x, y) tuples\n",
    "        alpha: Smaller = tighter fit, larger = looser fit\n",
    "    \n",
    "    Returns:\n",
    "        remaining_points: Points not in the outer layer\n",
    "        layer_points: Points in the outer layer\n",
    "    \"\"\"\n",
    "    # Create alpha shape (concave hull)\n",
    "    alpha_shape = alphashape.alphashape(points, alpha)\n",
    "    \n",
    "    # Extract boundary coordinates\n",
    "    layer_coords = []\n",
    "    if isinstance(alpha_shape, Polygon):\n",
    "        layer_coords = list(alpha_shape.exterior.coords)\n",
    "    elif isinstance(alpha_shape, MultiPolygon):\n",
    "        for polygon in alpha_shape.geoms:\n",
    "            layer_coords.extend(list(polygon.exterior.coords))\n",
    "    \n",
    "    # Remove layer points from original points\n",
    "    layer_coords_set = set(layer_coords)\n",
    "    remaining_points = [p for p in points if p not in layer_coords_set]\n",
    "    \n",
    "    return remaining_points, layer_coords\n",
    "\n",
    "def detect_layers(cluster_points, alpha=0.01, max_layers=10):\n",
    "    \"\"\"\n",
    "    Iteratively detect layers in a cluster of points.\n",
    "    \n",
    "    Returns:\n",
    "        layers: {0: [(x, y), ...], 1: [(x, y), ...], ...}\n",
    "    \"\"\"\n",
    "    layers = {}\n",
    "    current_points = cluster_points.copy()\n",
    "    \n",
    "    for layer_id in range(max_layers):\n",
    "        if len(current_points) < 4:  # Need at least 4 points for alpha shape\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            current_points, layer_coords = extract_layer(current_points, alpha)\n",
    "            layers[layer_id] = layer_coords\n",
    "            \n",
    "            if not current_points:\n",
    "                print(f\"All points assigned to layers\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Stopped at layer {layer_id}: {e}\")\n",
    "            break\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6919895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a test image and visualize clusters\n",
    "test_image = images[1]\n",
    "test_clusters = cluster_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce10b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 12))\n",
    "# for region_idx, (region_id, points) in enumerate(test_clusters.items()):\n",
    "#     points_array = np.array(points)\n",
    "#     plt.scatter(points_array[:, 1], points_array[:, 0], s=20, alpha=0.5, label=f'Region {region_id}')\n",
    "\n",
    "# plt.title(f'Nuclei Clusters ({len(clusters)} regions)')\n",
    "# plt.legend(loc='upper right', fontsize=8)\n",
    "# plt.imshow(test_image)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d000855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_shapes = {}\n",
    "for region_id, cluster_points in test_clusters.items():\n",
    "    points_array = np.array(cluster_points)\n",
    "    alpha_shapes[region_id] = alphashape.alphashape(points_array, alpha=0.01)\n",
    "\n",
    "\n",
    "all_layer_coords = {}\n",
    "idx = 0\n",
    "for _, alpha_shape in alpha_shapes.items():\n",
    "    layer_coords = []\n",
    "    if isinstance(alpha_shape, Polygon):\n",
    "        layer_coords = list(alpha_shape.exterior.coords)\n",
    "    elif isinstance(alpha_shape, MultiPolygon):\n",
    "        for polygon in alpha_shape.geoms:\n",
    "            layer_coords.extend(list(polygon.exterior.coords))\n",
    "    if layer_coords:\n",
    "        all_layer_coords[idx] = layer_coords\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03daed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# axes[0].imshow(test_image)\n",
    "# region_colors = plt.cm.tab10(np.linspace(0, 1, len(test_clusters)))\n",
    "\n",
    "# for idx, (region_id, points) in enumerate(test_clusters.items()):\n",
    "#     points_array = np.array(points)\n",
    "#     axes[0].scatter(points_array[:, 1], points_array[:, 0], \n",
    "#                    c=[region_colors[idx]], s=20, alpha=0.6, \n",
    "#                    label=f'Region {region_id}')\n",
    "\n",
    "# axes[0].set_title(f'Nuclei Points ({len(test_clusters)} regions)')\n",
    "# axes[0].axis('off')\n",
    "# if len(test_clusters) <= 10:\n",
    "#     axes[0].legend()\n",
    "\n",
    "# axes[1].imshow(test_image)\n",
    "\n",
    "# for idx, layer_coords in all_layer_coords.items():\n",
    "#     layer_array = np.array(layer_coords)\n",
    "    \n",
    "#     axes[1].plot(layer_array[:, 1], layer_array[:, 0], \n",
    "#                 color=region_colors[idx % len(region_colors)], \n",
    "#                 linewidth=2.5, alpha=0.8,\n",
    "#                 label=f'Region {idx}')\n",
    "\n",
    "#     axes[1].fill(layer_array[:, 1], layer_array[:, 0], \n",
    "#                 color=region_colors[idx % len(region_colors)], \n",
    "#                 alpha=0.15)\n",
    "\n",
    "# axes[1].set_title('Alpha Shapes (Concave Hulls)')\n",
    "# axes[1].axis('off')\n",
    "# if len(all_layer_coords) <= 10:\n",
    "#     axes[1].legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76d1de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All points assigned to layers\n"
     ]
    }
   ],
   "source": [
    "test_layers = {}\n",
    "for region_id, cluster_points in test_clusters.items():\n",
    "    layers = detect_layers(cluster_points)\n",
    "    test_layers[region_id] = layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b71f2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image 1/4\n",
      "Processing Image 2/4\n",
      "Processing Image 3/4\n",
      "Processing Image 4/4\n"
     ]
    }
   ],
   "source": [
    "all_image_layers = []\n",
    "\n",
    "for img_idx, (image, clusters) in enumerate(zip(images, cluster_list)):\n",
    "    print(f\"Processing Image {img_idx + 1}/{len(images)}\")\n",
    "    \n",
    "    image_layers = {}\n",
    "    \n",
    "    for region_id, cluster_points in clusters.items():\n",
    "        \n",
    "        if len(cluster_points) < 10:\n",
    "            continue\n",
    "        \n",
    "        layers = detect_layers(cluster_points, alpha=0.01, max_layers=10)\n",
    "        image_layers[region_id] = layers\n",
    "    \n",
    "    all_image_layers.append(image_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "175159e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "# layer_colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "\n",
    "# for img_idx, (image, image_layers, clusters) in enumerate(zip(images, all_image_layers, cluster_list)):\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "    \n",
    "#     axes[0].imshow(image)\n",
    "#     axes[0].set_title(f'Image {img_idx + 1}: Original')\n",
    "#     axes[0].axis('off')\n",
    "    \n",
    "#     axes[1].imshow(image)\n",
    "#     region_colors = plt.cm.tab10(np.linspace(0, 1, max(len(clusters), 1)))\n",
    "    \n",
    "#     for region_idx, (region_id, points) in enumerate(clusters.items()):\n",
    "#         points_array = np.array(points)\n",
    "#         axes[1].scatter(points_array[:, 1], points_array[:, 0], \n",
    "#                        c=[region_colors[region_idx % len(region_colors)]], \n",
    "#                        s=10, alpha=0.5, label=f'Region {region_id}')\n",
    "    \n",
    "#     axes[1].set_title(f'Nuclei Clusters ({len(clusters)} regions)')\n",
    "#     axes[1].axis('off')\n",
    "#     if len(clusters) <= 10:\n",
    "#         axes[1].legend(loc='upper right', fontsize=8)\n",
    "    \n",
    "#     axes[2].imshow(image)\n",
    "    \n",
    "#     for region_id, layers in image_layers.items():\n",
    "#         for layer_id, layer_points in layers.items():\n",
    "#             if len(layer_points) > 0:\n",
    "#                 layer_array = np.array(layer_points)\n",
    "#                 axes[2].plot(layer_array[:, 1], layer_array[:, 0], \n",
    "#                            color=layer_colors[layer_id % len(layer_colors)], \n",
    "#                            linewidth=2.5, alpha=0.8,\n",
    "#                            label=f'Layer {layer_id}' if region_id == list(image_layers.keys())[0] else '')\n",
    "    \n",
    "#     axes[2].set_title(f'Detected Layers (colored by depth)')\n",
    "#     axes[2].axis('off')\n",
    "    \n",
    "\n",
    "#     handles, labels = axes[2].get_legend_handles_labels()\n",
    "#     by_label = dict(zip(labels, handles))\n",
    "#     axes[2].legend(by_label.values(), by_label.keys(), loc='upper right', fontsize=8)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a37a7",
   "metadata": {},
   "source": [
    "### Try HDBSCAN for better Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21b8b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "def create_hdbscan_clusters(tissue_labeled: np.ndarray, data_dict: dict[str,any], cluster_size_fraction: float, min_samples_fraction) -> dict[int, list]:\n",
    "    nucleus_centers = data_dict['points']\n",
    "\n",
    "    number_of_points = len(nucleus_centers)\n",
    "    number_of_tissues = len(np.unique(tissue_labeled)) - 1\n",
    "    expected_per_tissue = number_of_points / max(number_of_tissues, 1)\n",
    "\n",
    "    min_cluster_size = max(5, int(expected_per_tissue * 0.2))\n",
    "    min_samples = max(3, int(min_cluster_size * min_samples_fraction))\n",
    "\n",
    "    filtered_centers = []\n",
    "    for x, y in nucleus_centers:\n",
    "        x_int, y_int = int(x), int(y)\n",
    "        \n",
    "        if 0 <= x_int < tissue_labeled.shape[0] and 0 <= y_int < tissue_labeled.shape[1]:\n",
    "            region_id = tissue_labeled[x_int, y_int]\n",
    "            \n",
    "            if region_id > 0:\n",
    "                filtered_centers.append((x, y))\n",
    "    \n",
    "    if len(filtered_centers) < 2:\n",
    "        cluster_list.append({})\n",
    "    \n",
    "    points_array = np.array(filtered_centers)\n",
    "    \n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples)\n",
    "    labels = clusterer.fit_predict(points_array)\n",
    "\n",
    "    clusters = {}\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        \n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        \n",
    "        clusters[label].append(tuple(filtered_centers[idx]))\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c72cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_fractions = np.arange(0, 1.05, 0.05) \n",
    "sample_fractions = np.arange(0, 1.05, 0.05) \n",
    "TARGET_CLUSTERS = np.array([10, 8, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92ac6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"'force_all_finite' was renamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1d890b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new best values! Best cluster fraction: 0.0, best sample fraction: 0.0\n",
      "Found new best values! Best cluster fraction: 0.0, best sample fraction: 0.15000000000000002\n",
      "Found new best values! Best cluster fraction: 0.0, best sample fraction: 0.4\n",
      "Found new best values! Best cluster fraction: 0.0, best sample fraction: 0.5\n",
      "Found new best values! Best cluster fraction: 0.0, best sample fraction: 0.8\n",
      "Found new best values! Best cluster fraction: 0.0, best sample fraction: 0.9500000000000001\n"
     ]
    }
   ],
   "source": [
    "best_cluster_fraction = 0\n",
    "best_sample_fraction = 0\n",
    "best_similarity = float(\"inf\")\n",
    "\n",
    "for cluster_fraction in cluster_fractions:\n",
    "    for sample_fraction in sample_fractions:\n",
    "        cluster_list = []\n",
    "        for tissue_labeled, data_dict in zip(labeled_tissues, nuclei_data_dicts):\n",
    "            clusters = create_hdbscan_clusters(tissue_labeled, data_dict, cluster_fraction, sample_fraction)\n",
    "            cluster_list.append(len(clusters))\n",
    "        \n",
    "        cluster_list = np.array(cluster_list)\n",
    "        norm = np.linalg.norm(cluster_list - TARGET_CLUSTERS)\n",
    "        if norm < best_similarity:\n",
    "            best_similarity = norm\n",
    "            best_cluster_fraction = cluster_fraction\n",
    "            best_sample_fraction = sample_fraction\n",
    "            print(f\"Found new best values! Best cluster fraction: {best_cluster_fraction}, best sample fraction: {best_sample_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce27ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_cluster_list = []\n",
    "for tissue_labeled, data_dict in zip(labeled_tissues, nuclei_data_dicts):\n",
    "    clusters = create_hdbscan_clusters(tissue_labeled, data_dict, best_cluster_fraction, best_sample_fraction)\n",
    "    hdb_cluster_list.append(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71ca1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, hdb_cluster, nuclei_mask in zip(images, hdb_cluster_list, nuclei_masks):\n",
    "#     plt.figure(figsize=(18, 12))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(nuclei_mask)\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     for region_idx, (region_id, points) in enumerate(hdb_cluster.items()):\n",
    "#         points_array = np.array(points)\n",
    "#         plt.scatter(points_array[:, 1], points_array[:, 0], s=10, alpha=0.7, label=f'Region {region_id}')\n",
    "\n",
    "\n",
    "#     plt.title(f'Nuclei Clusters ({len(hdb_cluster)} regions)')\n",
    "#     #plt.legend(loc='upper right', fontsize=8)\n",
    "#     plt.imshow(image)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed356b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image 1/4\n",
      "All points assigned to layers\n",
      "All points assigned to layers\n",
      "All points assigned to layers\n",
      "Processing Image 2/4\n",
      "Processing Image 3/4\n",
      "Processing Image 4/4\n"
     ]
    }
   ],
   "source": [
    "hdb_all_image_layers = []\n",
    "\n",
    "for img_idx, (image, clusters) in enumerate(zip(images, hdb_cluster_list)):\n",
    "    print(f\"Processing Image {img_idx + 1}/{len(images)}\")\n",
    "    \n",
    "    image_layers = {}\n",
    "\n",
    "    stats = df.iloc[img_idx]\n",
    "    median_nuclei_size = stats[\"median_nuclei_size\"] * 0.001\n",
    "    \n",
    "    for region_id, cluster_points in clusters.items():\n",
    "        \n",
    "        if len(cluster_points) < 10:\n",
    "            continue\n",
    "        \n",
    "        layers = detect_layers(cluster_points, alpha=0.01, max_layers=10)\n",
    "        image_layers[region_id] = layers\n",
    "    \n",
    "    hdb_all_image_layers.append(image_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59685e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    428.0\n",
       "1    616.0\n",
       "2    537.0\n",
       "3    352.0\n",
       "Name: median_nuclei_size, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"median_nuclei_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cfffe3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "# layer_colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "\n",
    "# for img_idx, (image, image_layers, clusters) in enumerate(zip(images, hdb_all_image_layers, hdb_cluster_list)):\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "    \n",
    "#     axes[0].imshow(image)\n",
    "#     axes[0].set_title(f'Image {img_idx + 1}: Original')\n",
    "#     axes[0].axis('off')\n",
    "    \n",
    "#     axes[1].imshow(image)\n",
    "#     region_colors = plt.cm.tab10(np.linspace(0, 1, max(len(clusters), 1)))\n",
    "    \n",
    "#     for region_idx, (region_id, points) in enumerate(clusters.items()):\n",
    "#         points_array = np.array(points)\n",
    "#         axes[1].scatter(points_array[:, 1], points_array[:, 0], \n",
    "#                        c=[region_colors[region_idx % len(region_colors)]], \n",
    "#                        s=10, alpha=0.5, label=f'Region {region_id}')\n",
    "    \n",
    "#     axes[1].set_title(f'Nuclei Clusters ({len(clusters)} regions)')\n",
    "#     axes[1].axis('off')\n",
    "#     if len(clusters) <= 10:\n",
    "#         axes[1].legend(loc='upper right', fontsize=8)\n",
    "    \n",
    "#     axes[2].imshow(image)\n",
    "    \n",
    "#     for region_id, layers in image_layers.items():\n",
    "#         for layer_id, layer_points in layers.items():\n",
    "#             if len(layer_points) > 0:\n",
    "#                 layer_array = np.array(layer_points)\n",
    "#                 axes[2].plot(layer_array[:, 1], layer_array[:, 0], \n",
    "#                            color=layer_colors[layer_id % len(layer_colors)], \n",
    "#                            linewidth=2.5, alpha=0.8,\n",
    "#                            label=f'Layer {layer_id}' if region_id == list(image_layers.keys())[0] else '')\n",
    "    \n",
    "#     axes[2].set_title(f'Detected Layers (colored by depth)')\n",
    "#     axes[2].axis('off')\n",
    "    \n",
    "\n",
    "#     handles, labels = axes[2].get_legend_handles_labels()\n",
    "#     by_label = dict(zip(labels, handles))\n",
    "#     axes[2].legend(by_label.values(), by_label.keys(), loc='upper right', fontsize=8)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f7f6d",
   "metadata": {},
   "source": [
    "### Iterative layer approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "472c5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dict = nuclei_data_dicts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3255673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['coord', 'points', 'prob'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3472a22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1216.    , 1218.2001, 1220.3412, 1222.0779, 1223.7898, 1225.5178,\n",
       "       1226.9631, 1227.9491, 1228.8011, 1228.3591, 1227.829 , 1226.3602,\n",
       "       1224.6915, 1222.7585, 1220.7545, 1218.3894, 1216.    , 1213.5497,\n",
       "       1211.0656, 1209.0938, 1207.5558, 1206.4421, 1205.4302, 1205.199 ,\n",
       "       1204.587 , 1204.9575, 1204.9989, 1205.871 , 1206.9973, 1208.9211,\n",
       "       1211.119 , 1213.6681], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dict[\"coord\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf3d9a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2129.422 , 2129.515 , 2129.739 , 2128.9075, 2127.6082, 2125.6465,\n",
       "       2123.2512, 2120.5698, 2118.    , 2115.4695, 2112.9644, 2110.8137,\n",
       "       2109.136 , 2107.5898, 2106.5623, 2106.0505, 2105.2817, 2105.4067,\n",
       "       2105.3987, 2106.194 , 2107.4004, 2109.3662, 2111.903 , 2115.    ,\n",
       "       2118.    , 2120.8035, 2123.3523, 2125.2053, 2126.5366, 2127.4512,\n",
       "       2128.4377, 2128.7634], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dict[\"coord\"][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5fd039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_dict[\"coord\"][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76274e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 403 After: 240\n"
     ]
    }
   ],
   "source": [
    "test_points = np.array(test_data_dict[\"points\"])\n",
    "test_mask = masks[1]\n",
    "\n",
    "filtered_points = [\n",
    "    p for p in test_points\n",
    "    if test_mask[int(p[0]), int(p[1])] != 0\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Before:\", len(test_points), \"After:\", len(filtered_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e7be1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "633c0436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(filtered_points).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea38f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points = np.array(filtered_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b58d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tri = Delaunay(test_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50f87a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.imshow(images[1])\n",
    "# plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "059d2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.imshow(images[1])\n",
    "# plt.triplot(test_points[:, 1], test_points[:, 0], test_tri.simplices, \n",
    "#             color='red', linewidth=0.5, alpha=0.7)\n",
    "# plt.plot(test_points[:, 1], test_points[:, 0], 'o', \n",
    "#          color='blue', markersize=3, alpha=0.8)\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dfe980a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delaunay_neighbors(points):\n",
    "    \"\"\"Build a neighbor dictionary from Delaunay triangulation.\"\"\"\n",
    "    points = np.array(points)\n",
    "    tri = Delaunay(points)\n",
    "    \n",
    "    neighbors = defaultdict(set)\n",
    "    \n",
    "    for simplex in tri.simplices:\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i != j:\n",
    "                    neighbors[simplex[i]].add(simplex[j])\n",
    "    \n",
    "    return dict(neighbors), points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45e24c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors, points_array = get_delaunay_neighbors(test_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94444155",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_indices = neighbors[0]\n",
    "point_0_coords = points_array[0]\n",
    "neighbor_coords = points_array[list(neighbor_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3cba0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of 5:  [18, 6, 42, 217, 113, 26, 165]\n",
      "Pos of node 5:  (1542, 872)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def build_neighbor_graph(points):\n",
    "    \"\"\"Build a NetworkX graph from Delaunay triangulation.\"\"\"\n",
    "    points = np.array(points)\n",
    "    tri = Delaunay(points)\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for i, (x, y) in enumerate(points):\n",
    "        G.add_node(i, pos=(x, y))\n",
    "    \n",
    "    for simplex in tri.simplices:\n",
    "        for i in range(3):\n",
    "            for j in range(i+1, 3):\n",
    "                p1, p2 = points[simplex[i]], points[simplex[j]]\n",
    "                dist = np.linalg.norm(p1 - p2)\n",
    "                G.add_edge(simplex[i], simplex[j], weight=dist)\n",
    "    \n",
    "    return G\n",
    "\n",
    "G = build_neighbor_graph(test_points)\n",
    "\n",
    "neighbors_of_5 = list(G.neighbors(5))\n",
    "print(\"Neighbors of 5: \", neighbors_of_5)\n",
    "\n",
    "pos = G.nodes[5]['pos']\n",
    "print(\"Pos of node 5: \", pos)\n",
    "\n",
    "for node in G.nodes():\n",
    "    for neighbor in G.neighbors(node):\n",
    "        edge_length = G[node][neighbor]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdf3ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nuclei_data_dict(stardist_data_dict):\n",
    "    \"\"\"\n",
    "    stardist_data_dict: whatever object you have per image; must contain:\n",
    "      - 'points': nuclei centroids in same order as coord entries\n",
    "      - 'coord': list/array of length N, each entry is ([x1..x32], [y1..y32])\n",
    "    Returns: dict idx -> {'boundary': np.ndarray shape (32,2)}\n",
    "    \"\"\"\n",
    "    nuclei_dict = {}\n",
    "    coords_all = stardist_data_dict['coord']\n",
    "    for idx, coord_pair in enumerate(coords_all):\n",
    "        xs, ys = coord_pair\n",
    "        boundary = np.stack([xs, ys], axis=1)\n",
    "        nuclei_dict[idx] = {'boundary': boundary}\n",
    "    return nuclei_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3157ec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best starting point: 137 with alignment score: 0.977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def get_nucleus_orientation(boundary_points):\n",
    "    \"\"\"\n",
    "    Extract main axis (orientation) of a nucleus from boundary points.\n",
    "    Returns: unit vector representing the main axis direction\n",
    "    \"\"\"\n",
    "    boundary_points = np.array(boundary_points)\n",
    "    \n",
    "    # Center the points\n",
    "    centroid = boundary_points.mean(axis=0)\n",
    "    centered = boundary_points - centroid\n",
    "    \n",
    "    # PCA to find main axis\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(centered)\n",
    "    \n",
    "    # First principal component is the main axis\n",
    "    main_axis = pca.components_[0]\n",
    "    \n",
    "    return main_axis\n",
    "\n",
    "def calculate_alignment_with_orientations(neighbors_dict, points_array, nuclei_data_dict):\n",
    "    \"\"\"\n",
    "    Calculate alignment score based on cosine similarity of nucleus orientations.\n",
    "    \n",
    "    Returns: dict mapping point_index -> alignment_score\n",
    "    \"\"\"\n",
    "    alignments = {}\n",
    "    \n",
    "    for point_idx in neighbors_dict:\n",
    "        neighbor_indices = list(neighbors_dict[point_idx])\n",
    "        \n",
    "        if len(neighbor_indices) < 2:\n",
    "            alignments[point_idx] = 0.0\n",
    "            continue\n",
    "        \n",
    "        if point_idx not in nuclei_data_dict or 'boundary' not in nuclei_data_dict[point_idx]:\n",
    "            alignments[point_idx] = 0.0\n",
    "            continue\n",
    "            \n",
    "        current_orientation = get_nucleus_orientation(nuclei_data_dict[point_idx]['boundary'])\n",
    "        \n",
    "        similarities = []\n",
    "        for neighbor_idx in neighbor_indices:\n",
    "            if neighbor_idx in nuclei_data_dict and 'boundary' in nuclei_data_dict[neighbor_idx]:\n",
    "                neighbor_orientation = get_nucleus_orientation(nuclei_data_dict[neighbor_idx]['boundary'])\n",
    "                \n",
    "                # Cosine similarity (1 - cosine distance)\n",
    "                # High similarity -> good alignment\n",
    "                similarity = abs(1 - cosine(current_orientation, neighbor_orientation))\n",
    "                similarities.append(similarity)\n",
    "        \n",
    "        if similarities:\n",
    "            alignments[point_idx] = np.mean(similarities)\n",
    "        else:\n",
    "            alignments[point_idx] = 0.0\n",
    "    \n",
    "    return alignments\n",
    "\n",
    "neighbors_dict, points_array = get_delaunay_neighbors(test_points)\n",
    "\n",
    "nuclei_data_dict = update_nuclei_data_dict(test_data_dict)\n",
    "\n",
    "alignments = calculate_alignment_with_orientations(neighbors_dict, points_array, nuclei_data_dict)\n",
    "\n",
    "best_start = max(alignments, key=alignments.get)\n",
    "print(f\"Best starting point: {best_start} with alignment score: {alignments[best_start]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eacf894b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1328, 1170])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_starting_coord = points_array[best_start]\n",
    "best_starting_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebf1c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.imshow(images[1])\n",
    "# plt.plot(best_starting_coord[1], best_starting_coord[0], 'o', \n",
    "#          color='blue', markersize=5, alpha=1.0)\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb0855ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_graph(points, neighbors_dict, nuclei_data_dict):\n",
    "    orientations = {}\n",
    "    for i, data in nuclei_data_dict.items():\n",
    "        if 'boundary' in data:\n",
    "            orientations[i] = get_nucleus_orientation(data['boundary'])\n",
    "\n",
    "    edge_sim = {}\n",
    "    edge_dist = {}\n",
    "    for u, nbrs in neighbors_dict.items():\n",
    "        for v in nbrs:\n",
    "            if u < v:\n",
    "                d = np.linalg.norm(points[u] - points[v])\n",
    "                edge_dist[(u, v)] = d\n",
    "                if u in orientations and v in orientations:\n",
    "                    s = abs(1 - cosine(orientations[u], orientations[v]))\n",
    "                else:\n",
    "                    s = -1\n",
    "                edge_sim[(u, v)] = s\n",
    "    return orientations, edge_dist, edge_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32b07049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_layer(start, neighbors_dict, edge_dist, edge_sim,\n",
    "               sim_thresh=0.6, dist_thresh=50.0):\n",
    "    visited = set([start])\n",
    "    frontier = [start]\n",
    "    layer = [start]\n",
    "\n",
    "    while frontier:\n",
    "        u = frontier.pop()\n",
    "\n",
    "        candidates = []\n",
    "        for v in neighbors_dict[u]:\n",
    "            key = (u, v) if (u, v) in edge_sim else (v, u)\n",
    "            if key not in edge_sim or key not in edge_dist:\n",
    "                continue\n",
    "            s = edge_sim[key]\n",
    "            d = edge_dist[key]\n",
    "            if s >= sim_thresh and d <= dist_thresh:\n",
    "                candidates.append((s, v))\n",
    "\n",
    "        # Keep only the top-2 by similarity\n",
    "        candidates.sort(reverse=True, key=lambda x: x[0])\n",
    "        for _, v in candidates[:2]:\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                frontier.append(v)\n",
    "                layer.append(v)\n",
    "\n",
    "    return layer, visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c4295ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_to_explore = dict(alignments)\n",
    "layers = []\n",
    "orientations, edge_dist, edge_sim = prepare_graph(test_points, neighbors_dict, nuclei_data_dict)\n",
    "\n",
    "while nuclei_to_explore:\n",
    "    best_start = max(nuclei_to_explore, key=nuclei_to_explore.get)\n",
    "    layer, visited = grow_layer(best_start, neighbors_dict, edge_dist, edge_sim)\n",
    "    \n",
    "    if len(layer) > 1:\n",
    "        layers.append(layer)\n",
    "    \n",
    "    for idx in visited:\n",
    "        nuclei_to_explore.pop(idx, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed5a8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def plot_layers(image, points, layers, point_order=\"xy\"):\n",
    "#     \"\"\"\n",
    "#     image: 2D or 3D array\n",
    "#     points: array-like of shape (N, 2)\n",
    "#     layers: list of lists of point indices\n",
    "#     point_order: \"xy\" if points are (x, y); \"yx\" if points are (row, col)\n",
    "#     \"\"\"\n",
    "#     points = np.array(points)\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     h, w = image.shape[:2]\n",
    "#     plt.imshow(image, cmap='gray', extent=[0, w, h, 0])\n",
    "    \n",
    "#     colors = plt.cm.tab20(np.linspace(0, 1, max(1, len(layers))))\n",
    "    \n",
    "#     for i, layer in enumerate(layers):\n",
    "#         coords = points[layer]\n",
    "#         if point_order == \"xy\":\n",
    "#             xs, ys = coords[:, 0], coords[:, 1]\n",
    "#         else:\n",
    "#             ys, xs = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "#         plt.scatter(xs, ys, s=20, color=colors[i], alpha=0.9, label=f\"Layer {i+1}\")\n",
    "        \n",
    "#         # Connect points in order of layer list (greedy path)\n",
    "#         plt.plot(xs, ys, color=colors[i], alpha=0.6, linewidth=1)\n",
    "\n",
    "#     plt.axis('off')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_layers(images[1], test_points, layers, point_order=\"yx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d18bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
