{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e70b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6f0b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/research_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/research_project/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.data.dataset import PixelClassificationDataset\n",
    "from src.utils.helpers import get_image_and_mask_paths, compare_two_images\n",
    "from src.models.model_loader import ModelLoader\n",
    "\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07703b7d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119540c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/cnn_training/resized_images\"\n",
    "MASK_DIR = \"data/cnn_training/resized_masks\"\n",
    "ORG_RES = (1920, 2560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec51432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths, train_mask_paths, test_image_paths, test_mask_paths = (\n",
    "    get_image_and_mask_paths(DATA_DIR, MASK_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8b2b5",
   "metadata": {},
   "source": [
    "# Evaluate three class predictions qualitatively per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e183457",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PixelClassificationDataset(\n",
    "    image_paths=test_image_paths,\n",
    "    mask_paths=test_mask_paths,\n",
    "    transform=None,\n",
    "    augmentations_per_image=1,\n",
    "    include_original=True,\n",
    "    binary_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a32c917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CNN: UNet_3\n",
      "Loaded CNN: UNet++_3\n",
      "Loaded CNN: DeepLabV3_3\n",
      "Loaded CNN: UNet_basic_3\n",
      "Model loaded from: /Users/levin/Documents/Uni/Master/semester_3/research_project/ASON/checkpoints/random_forest_balanced.joblib\n",
      "Loaded RF: Random Forest\n",
      "Loaded 5 models total\n",
      "Loaded Models:\n",
      "------------------------------------------------------------\n",
      "UNet_3                         [cnn] unet_resnet34_imagenet_3c.pth\n",
      "UNet++_3                       [cnn] unet++_resnet34_imagenet_3c.pth\n",
      "DeepLabV3_3                    [cnn] deeplabv3_resnet34_imagenet_3c.pth\n",
      "UNet_basic_3                   [cnn] unet_no_weights_3c.pth\n",
      "Random Forest                  [rf ] random_forest_balanced.joblib\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "three_class_loader = ModelLoader(project_root)\n",
    "\n",
    "# Load all models for three classes\n",
    "three_class_loader.load_all_models({\n",
    "    \"UNet_3\": (\"unet_3\", \"cnn\"),\n",
    "    \"UNet++_3\": (\"unet++_3\", \"cnn\"),\n",
    "    \"DeepLabV3_3\": (\"deeplabv3_3\", \"cnn\"),\n",
    "    \"UNet_basic_3\": (\"unet_basic_3\", \"cnn\"),\n",
    "    \"Random Forest\": (\"random_forest\", \"rf\"),\n",
    "})\n",
    "\n",
    "model_names = three_class_loader.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97cb89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name in model_names:\n",
    "#     model = three_class_loader.get_model(model_name)\n",
    "#     model_type = model_names[model_name]\n",
    "#     print(\"=\"*100)\n",
    "#     print(f\"Evaluating model: {model_name}\")\n",
    "#     for i in range(len(test_dataset)):\n",
    "#         test_image_tensor, test_mask_tensor = test_dataset[i]\n",
    "\n",
    "#         if model_type == \"rf\":\n",
    "#             test_image = test_image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "#             test_image = (test_image * 255).astype(np.uint8)\n",
    "#             pred_mask = model(test_image)\n",
    "        \n",
    "#         else:\n",
    "#             test_image_tensor = test_image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 pred_logits = model(test_image_tensor)\n",
    "#                 pred_mask = torch.argmax(pred_logits, dim=1).squeeze()\n",
    "#                 pred_mask = pred_mask.cpu().numpy()\n",
    "\n",
    "#         test_mask = test_mask_tensor.numpy()\n",
    "#         original_image = tifffile.imread(test_image_paths[i])\n",
    "        \n",
    "#         plt.imshow(original_image)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.title(\"Original Image\")\n",
    "#         plt.show()\n",
    "\n",
    "#         compare_two_images(pred_mask, test_mask, \"Predicted Mask\", \"Original Mask\")\n",
    "        \n",
    "#         pred_mask_org = resize(pred_mask, ORG_RES, anti_aliasing=True)\n",
    "#         test_mask_org = resize(test_mask, ORG_RES, anti_aliasing=True)\n",
    "#         compare_two_images(pred_mask_org, test_mask_org, \"Predicted Mask ORG\", \"Original Mask ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "255738f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(test_dataset)):\n",
    "#     test_image_tensor, test_mask_tensor = test_dataset[i]\n",
    "#     test_mask = test_mask_tensor.numpy()\n",
    "#     test_mask_org = resize(test_mask, ORG_RES, anti_aliasing=True)\n",
    "#     plt.figure(figsize=(60, 10))\n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.imshow(test_mask_org)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(\"Original Mask\")\n",
    "\n",
    "#     test_image = test_image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "#     test_image = (test_image * 255).astype(np.uint8)\n",
    "\n",
    "#     test_image_tensor = test_image_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "#     for i, model_name in enumerate(model_names):\n",
    "#         model = three_class_loader.get_model(model_name)\n",
    "#         model_type = model_names[model_name]\n",
    "        \n",
    "#         if model_type == \"rf\":\n",
    "#             pred_mask = model(test_image)\n",
    "        \n",
    "#         else:\n",
    "#             with torch.no_grad():\n",
    "#                 pred_logits = model(test_image_tensor)\n",
    "#                 pred_mask = torch.argmax(pred_logits, dim=1).squeeze()\n",
    "#                 pred_mask = pred_mask.cpu().numpy()\n",
    "        \n",
    "#         pred_mask_org = resize(pred_mask, ORG_RES, anti_aliasing=True)\n",
    "        \n",
    "#         plt.subplot(1, 6, i+2)\n",
    "#         plt.imshow(pred_mask_org)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.title(f\"{model_name}\")\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85ae14",
   "metadata": {},
   "source": [
    "Overall, the normal pretrained Unet architecture or the DeepLabV3 model seem to produce the best results, one possibility could be to average the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a3190",
   "metadata": {},
   "source": [
    "# Evaluate two class predictions qualitatively per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e56ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PixelClassificationDataset(\n",
    "    image_paths=test_image_paths,\n",
    "    mask_paths=test_mask_paths,\n",
    "    transform=None,\n",
    "    augmentations_per_image=1,\n",
    "    include_original=True,\n",
    "    binary_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6396d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CNN: UNet_2\n",
      "Loaded CNN: UNet++_2\n",
      "Loaded CNN: DeepLabV3_2\n",
      "Loaded CNN: UNet_basic_2\n",
      "Model loaded from: /Users/levin/Documents/Uni/Master/semester_3/research_project/ASON/checkpoints/random_forest_2c_balanced.joblib\n",
      "Loaded RF: Random Forest_2\n",
      "Loaded 5 models total\n",
      "Loaded Models:\n",
      "------------------------------------------------------------\n",
      "UNet_2                         [cnn] unet_resnet34_imagenet_2c.pth\n",
      "UNet++_2                       [cnn] unet++_resnet34_imagenet_2c.pth\n",
      "DeepLabV3_2                    [cnn] deeplabv3_resnet34_imagenet_2c.pth\n",
      "UNet_basic_2                   [cnn] unet_no_weights_2c.pth\n",
      "Random Forest_2                [rf ] random_forest_2c_balanced.joblib\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "two_class_loader = ModelLoader(project_root)\n",
    "\n",
    "# Load all models for three classes\n",
    "two_class_loader.load_all_models({\n",
    "    \"UNet_2\": (\"unet_2\", \"cnn\"),\n",
    "    \"UNet++_2\": (\"unet++_2\", \"cnn\"),\n",
    "    \"DeepLabV3_2\": (\"deeplabv3_2\", \"cnn\"),\n",
    "    \"UNet_basic_2\": (\"unet_basic_2\", \"cnn\"),\n",
    "    \"Random Forest_2\": (\"random_forest_2\", \"rf\"),\n",
    "})\n",
    "\n",
    "model_names = two_class_loader.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c428fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name in model_names:\n",
    "#     model = two_class_loader.get_model(model_name)\n",
    "#     model_type = model_names[model_name]\n",
    "#     print(\"=\"*100)\n",
    "#     print(f\"Evaluating model: {model_name}\")\n",
    "#     for i in range(len(test_dataset)):\n",
    "#         test_image_tensor, test_mask_tensor = test_dataset[i]\n",
    "\n",
    "#         if model_type == \"rf\":\n",
    "#             test_image = test_image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "#             test_image = (test_image * 255).astype(np.uint8)\n",
    "#             pred_mask = model(test_image)\n",
    "        \n",
    "#         else:\n",
    "#             test_image_tensor = test_image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 pred_logits = model(test_image_tensor)\n",
    "#                 pred_mask = torch.argmax(pred_logits, dim=1).squeeze()\n",
    "#                 pred_mask = pred_mask.cpu().numpy()\n",
    "\n",
    "#         test_mask = test_mask_tensor.numpy()\n",
    "#         original_image = tifffile.imread(test_image_paths[i])\n",
    "        \n",
    "#         plt.imshow(original_image)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.title(\"Original Image\")\n",
    "#         plt.show()\n",
    "\n",
    "#         compare_two_images(pred_mask, test_mask, \"Predicted Mask\", \"Original Mask\")\n",
    "        \n",
    "#         pred_mask_org = resize(pred_mask, ORG_RES, anti_aliasing=True)\n",
    "#         test_mask_org = resize(test_mask, ORG_RES, anti_aliasing=True)\n",
    "#         compare_two_images(pred_mask_org, test_mask_org, \"Predicted Mask ORG\", \"Original Mask ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4965472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(test_dataset)):\n",
    "#     test_image_tensor, test_mask_tensor = test_dataset[i]\n",
    "#     test_mask = test_mask_tensor.numpy()\n",
    "#     test_mask_org = resize(test_mask, ORG_RES, anti_aliasing=True)\n",
    "#     plt.figure(figsize=(60, 10))\n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.imshow(test_mask_org)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(\"Original Mask\")\n",
    "\n",
    "#     test_image = test_image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "#     test_image = (test_image * 255).astype(np.uint8)\n",
    "\n",
    "#     test_image_tensor = test_image_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "#     for i, model_name in enumerate(model_names):\n",
    "#         model = two_class_loader.get_model(model_name)\n",
    "#         model_type = model_names[model_name]\n",
    "        \n",
    "#         if model_type == \"rf\":\n",
    "#             pred_mask = model(test_image)\n",
    "        \n",
    "#         else:\n",
    "#             with torch.no_grad():\n",
    "#                 pred_logits = model(test_image_tensor)\n",
    "#                 pred_mask = torch.argmax(pred_logits, dim=1).squeeze()\n",
    "#                 pred_mask = pred_mask.cpu().numpy()\n",
    "        \n",
    "#         pred_mask_org = resize(pred_mask, ORG_RES, anti_aliasing=True)\n",
    "        \n",
    "#         plt.subplot(1, 6, i+2)\n",
    "#         plt.imshow(pred_mask_org)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.title(f\"{model_name}\")\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46881fb8",
   "metadata": {},
   "source": [
    "We can see that the two class prediction task is way easier for the models, which is expected. From qualitative evaluation it seems again that Unet and DeepLabV3 are performing best, here a combination of both could be even better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc9afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
